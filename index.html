<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<title>Tolga Birdal: Researcher, entrepreneur, machine vision expert</title>
	<meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1">
	<meta charset="utf-8" name="author" content="Tolga Birdal">
	<meta charset="utf-8" name="keywords" content="academic, researcher, entrepreneur, start-up, personal, computer vision, machine learning, machine vision, pattern recognition, 3d, consultant, consulting, consultancy, Machine vision researcher">
	<meta charset="utf-8" name="description" content="An entrepreneur and researcher, working in the field of computer vision, augmented reality and pattern recognition. Contact me for machine vision projects and consulting.">	
	 <meta http-equiv="Content-Language" content="en">
	<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-XXXXX-X']);
  _gaq.push(['_setSiteSpeedSampleRate', 100]);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script');
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 
        'http://www') + '.google-analytics.com/ga.js';
    ga.setAttribute('async', 'true');
    document.documentElement.firstChild.appendChild(ga);
  })();

</script>
<noscript>Your browser does not support JavaScript.</noscript>
	<link rel="stylesheet" href="css/jquery.jscrollpane.min.css" />
	<link rel="stylesheet" href="css/normalize.min.css" />
	<link rel="stylesheet" href="css/boilerplate.min.css" />
	<link rel="stylesheet" href="css/icons/font-awesome.min.css" />
	<link rel="stylesheet" href="css/style.min.css" />
	<link rel="stylesheet" href="css/colors/red.min.css" id="color" />
	<link rel="stylesheet" href="css/colors/default.min.css" id="color" />
	<link rel="stylesheet" href="css/bjqs.min.css" />
	<link rel="stylesheet" href="css/jquery.lightbox.min.css" />
	<link href='http://fonts.googleapis.com/css?family=Ubuntu:300,400' rel='stylesheet' />
	<link rel="shortcut icon" type="image/x-icon" href="img/favicon/favicon.ico">
</head>
<body class="bg01"><div id="loading_page"><img src="img/loading.gif" alt="Please be patient while loading"></div>
	<div id="all" class="clearfix">
		
		<section id="leftSection">
			<div id="columnLeft" class="bgLight box-shadow box-sizing">
				<div class="content">
					<div class="inner">

						<div class="col c1">
							<section id="box-photo" class="box-sizing">
								<a href="#profile" class="menu">
									<img id="photo" alt="My Personal Photo" src="img/profile/photo.jpg" width="250" height="250" class="box-sizing inner-shadow" />
								</a>
							</section>
						</div>
						
						<div id="mainInfo">
							<h1 id="name" class="transition-02">Tolga Birdal</h1>
							<h2 class="line">Researcher & Entrepreneur</h2>
						</div>
						
						<section id="bio">
							<p>Tolga Birdal's personal web site.</p>		
                            <br>
                            <h3>News</h3>
      
  <ul style="background-color:#000000">
        <p><li style="background-color:#000000"><a href="https://profiles.stanford.edu/tolga-birdal" style="background-color:#000000">- I moved to Stanfor to further my research within the Geometric Computing Group.</a></li><p>
      <p><li style="background-color:#000000"><a href="https://mvr3d.github.io" style="background-color:#000000">- I happily co-organized ICCV 2017 Workshop on Multiview Relationships in 3D Data.</a></li><p>
      <p><li style="background-color:#000000"><a href="https://www.imveurope.com/news/analysis-opinion/rethinking-3d-vision" style="background-color:#000000">- Rethinking 3D Vision - IMV Europe Opinion Analysis.</a></li><p>
    <p><li style="background-color:#000000"><a href="http://www.imveurope.com/features/feature.php?feature_id=327" style="background-color:#000000">- My interview on IMV Europe.</a></li><p>
   <p> <li style="background-color:#000000"><article style="background-color:#000000"><a href="http://www.vision-systems.com/articles/2016/06/emva-2016-young-profesional-award-given-for-3d-reconstruction-framework.html" style="background-color:#000000">- I received EMVA Young Profesional Award 2016.</a></article></li><p>
  </ul>
						</section>
						
						<section id="social">
							<h2 class="line">Social Profiles</h2>
							<a href="https://www.linkedin.com/in/tbirdal" target="linkedin-tolga"><i class="fa fa-linkedin"></i></a>
                            <a href="https://www.youtube.com/channel/UCMSqZYDAmbiaAhyvLPJGhsg" target="youtube-tolga"><i class="fa fa-youtube"></i></a>                            
							<div class="clear"></div>
						</section>
					</div>
				</div>
			</div>
		</section>
		<section id="rightSection">
			<section id="top">
				<div class="content">
					
					<nav id="nav">
						<ul>
							<li><a href="#profile" id="profile" class="menu box-shadow active"><i class="fa fa-male"></i><span>Profile</span></a></li>
							<li><a href="#resume" id="resume" class="menu box-shadow"><i class="fa fa-file-text"></i><span>Resume</span></a></li>
							<li><a href="#blog" id="blog" class="menu box-shadow"><i class="fa fa-code-fork"></i><span>Research</span></a></li>
                            <li><a href="#apps" id="apps" class="menu box-shadow"><i class="fa fa-gears"></i><span>Applications</span></a></li>
                            <li><a href="#publications" id="publications" class="menu box-shadow"><i class="fa fa-book"></i><span>Publications</span></a></li>
                            <li><a href="#links" id="links" class="menu box-shadow"><i class="fa fa-link"></i><span>Miscellaneous</span></a></li>
						</ul>
						<div class="clear"></div>
					</nav>
				</div>
			</section>
			<div id="columnRight">
				<section id="page" class="scroll-pane box-shadow">
					<section id="profile-page" class="content">
						<div class="inner">
							<div class="col c2-1 first">
								<h3>About Me</h3>
								<ul class="about">
									<li>
										<label>Name:</label>
										<span class="value">Tolga Birdal</span><div class="clear"></div>
									</li>
									<li>
										<label>Birthday:</label>
										<span class="value">December 17, 1983</span><div class="clear"></div>
									</li>
									<li>
										<label>Email:</label>
										<span class="value">tbirdal (at) gmail (dot) com</span><div class="clear"></div>
									</li>
									<li>
										
									</li>
								</ul>
                                <p>Seeker of sophistication and unveiled tunes of life, voluntarily a thinker, and temporary tenant of the Earth. <br><br>
                                   Listens to jazz, plays drums, cooks, tastes, reads and solves.<br><br>
                                   
                                   Besides those, I am about to finish my PhD studies at Technical University of Munich, sponsored by Siemens AG. <br>
                                   As a co-founder and director of two great start-ups, I guess it would also be appropriate to define myself as an eager entrepreneur and machine vision expert, working in the field of computer vision, machine learning, augmented reality and pattern recognition. <br>
                                   Please feel free to contact me.
<p>I grew up in Izmir / Turkey, the most relaxed and liberal city of all and moved to Istanbul, the most chaotic of all. Presumably, those are the reasons why I love Jazz & Drumming, with a delicate taste of wine on the side.</p>

<p>Just enjoy.</p>
                                <br>
<p>
									<i class="fa fa-quote-left"></i>
									Wisdom is not a product of schooling, but a lifelong attempt to acquire it.<i class="fa fa-quote-right"></i>
									<span class="author">Albert Einstein</span>
								</p>
                                
							</div>

							<div class="col c2-1">
								<div id="image-rotator">
									<ul class="bjqs">
										<li><img src="img/profile/me_charlie.jpg" alt="Myself at Check Point Charlie"></li>
										<li><img src="img/profile/me_garden.jpg" alt="Myself at BeFunky office"></li>
									</ul>
								</div>
                                <div align="right"><p>Myself on Stack Exchange:</p><p></p>
                                
                                <a href="http://stackexchange.com/users/3756486/tbirdal"><img src="http://stackexchange.com/users/flair/3756486.png" width="180" height="50" target="_blank" alt="profile for Tolga Birdal on Stack Exchange, a network of free" title="profile for Tolga Birdal on Stack Exchange" /></a>
								
                                    </div>
							</div>
							<div class="clear"></div>
                            
                            <div class="clear"></div>
						</div>
					</section>
					<section id="resume-page" class="content">
						<div class="inner">
							<div class="col c2-1 first">
								<h4>Employment</h4>
								<ul class="attributes">
                                    <li class="first">
                                        <h5>Postdoctoral Research Fellow<span class="period">2019 - Present</span></h5>
										<h6><i class="fa fa-suitcase"></i>Stanford University</h6>
                                        <p>I am a member of the geometric computing group. My current research involves a diverse spectrum from geometry of high dimensional entities to 3D deep learning.
										</p>
                                        </li>
                                    <li class="first">
                                        <h5>Doktorand<span class="period">2014 - 2018</span></h5>
										<h6><i class="fa fa-suitcase"></i>Siemens AG</h6>
                                        <p>Siemens proudly sponsors my PhD studies on 3D object detection and reconstruction using CAD models.
										</p>
                                        </li>
									<li class="first">
                                        <h5>Co-Founder & CEO <span class="period">2011 - 2014</span></h5>
										<h6><i class="fa fa-suitcase"></i>Gravi Information Technologies and Consultancy Ltd.</h6>
										<p>Gravi Information Technologies and Consultancy Ltd is a Turkish start-up company founded in 2010 by a group of electronics and computer engineers (including myself) experienced in computer vision and computer graphics areas.
Gravi is supported by KOSGEB, which is a government organization supporting small and medium sized enterprises in Turkey, under the R & D Support Program.</p>
									</li>
									<li>
										<h5>Co-Founder & Chief Engineer<span class="period">2008 - 2011</span></h5>
										<h6><i class="fa fa-suitcase"></i>BeFunky Inc.</h6>
										<p>BeFunky Photo Effects allow everyday people to easily create photographically rich and artistic results from their digital images without the need for any technical knowledge. These "one-click" photo effect options produce desired results effortlessly and each effect comes with the option to make simple adjustments.</p>
									</li>
									<li>
										<h5>Intern<span class="period">2009</span></h5>
										<h6><i class="fa fa-suitcase"></i>Mitsubishi Electric Research Labs</h6>
										<p>Designing and developing an algorithm for simulating human breathing in 4D<br>
Implementation of Random Walks for Image Segmentation<br>
Implementation of true real-time Bilateral Filtering</p>
									</li>
                                    <li>
										<h5>Working Student<span class="period">2008 - 2010</span></h5>
										<h6><i class="fa fa-suitcase"></i>Technical University of Munich</h6>
										<p>I worked on 3D reconstruction system and extended it to 4D analysis. One other aspect of this work was visualization of temporal 3D volumetric data.</p>
									</li>
                                    <li>
										<h5>Intern<span class="period">2007</span></h5>
										<h6><i class="fa fa-suitcase"></i>Carnegie Mellon University</h6>
										<p>Worked on 3D optical avoidance under supervision of Assoc. Prof. Metin Sitti and shape matching using segmentation maps under supervision of Prof. Martial Hebert and Dr. Yan Ke.</p>
									</li>
                                    <li>
										<h5>Lead Developer<span class="period">2007 - 2008</span></h5>
										<h6><i class="fa fa-suitcase"></i>Vistek Isra Vision</h6>
										<p>I developed many industrial computer vision systems on OCR/OCV, Barcode Reading, Robot Control, Object Classification. I also designed complete systems using Halcon framework.</p>
									</li>
								</ul>
								<h4>Awards</h4>
								<ul class="attributes">
                                <li class="first">EMVA Young Proffesional Award 2016 (<a href="http://www.vision-systems.com/articles/2016/06/emva-2016-young-profesional-award-given-for-3d-reconstruction-framework.html" target="emva">News 1</a>, <a href="http://optics.org/press/3235" target="emva">News 2</a>)</li>
                                <li class="first">Received Ernst von Siemens Scholarship for High Success in PhD</li>
                                <li class="first">SIU Alper Atalay Best Paper Award - Ranked 3<sup>rd</sup></li>
								<li class="first">Sait Halman Computer Science Honor Prize at Robert College</li>
                                <li class="first">Motorolla Best Widget Award</li>
                                <li class="first">ITURO Robot Competition Award (2nd)</li>
                                <li class="first">Projistor Robot Competition Award (1st)</li>
                                <li class="first">Merit Scholarship, Sabanci University</li>
                                <li class="first">Ranked 10th in Agean Chess Tournament</li>
								</ul>
							</div>

							<div class="col c2-1">
                                <h4>Download My Resume</h4>
								<button class="btn" onClick="window.open('downloads/tolga-birdal-cv.pdf');" type="submit">
                                    <i class="fa fa-cloud-download"></i> Download as .PDF</button>
                                <ul class="attributes"></ul>
                                
								<h4>Education</h4>
								<ul class="attributes last">
									<li class="first">
										<h5>Ph.D. Candidate in Mathematics & Computer Science<p></p><span class="period">2014 - 2018</span></h5>
										<h6><i class="fa fa-book"></i>Technical University of Munich</h6>
										<p><b>Doctor Rerum Naturalium (PhD)</b></p>
                                        <p>Thesis: Geometric Methods for 3D Reconstruction from Large Point Clouds</p>
									</li>
									<li>
										<h5>M.Sc. in Computational Science & Engineering<p></p><span class="period">2008 - 2011</span></h5>
										<h6><i class="fa fa-book"></i>Technical University of Munich</h6>
										<p>Master's Thesis: 3D Deformable Surface Recovery Using RGBD Cameras</p>
									</li>
                                    <li>
										<h5>B.A. in Electronics Engineering<p></p><span class="period">2004 - 2008</span></h5>
										<h6><i class="fa fa-book"></i>Sabanci University</h6>
										<p>Undergraduate Thesis: VAPMed - A Medical Imaging Framework for Collaborative Research</p>
									</li>
                                    <li>
										<h5>Science Diploma<p></p><span class="period">1999 - 2004</span></h5>
										<h6><i class="fa fa-book"></i>Robert College</h6>
										<p>Robert College is proudly the best high school in Turkey.</p>
									</li>
                                    <li>
										<h5>Science Diploma<p></p><span class="period">1996 - 1999</span></h5>
										<h6><i class="fa fa-book"></i>Bornova Anatolian High School</h6>
										<p>This is the place where my first step to academic life was taken.</p>
									</li>
								</ul>
                                
								<h4>Software Skills</h4>
								<ul class="attributes">
								<li class="first">C, C++, C#, Java</li>
                                <li class="first">Assembler - SSE2 - SSE4.1, AVX</li>
                                <li class="first">CUDA, OpenMP, OpenCL</li>
                                <li class="first">MATLAB, Maple</li>
								<li class="first">OpenCV, OpenGL, PCL, Halcon, Visionscape, VTK</li>
                                <li class="first">Blas, Lapack, and other numerical libraries</li>
								<li class="first">Sketchup, Rhino3D</li>
                                <li class="first">Actionscript, Javascript, SQL</li>
                                <li class="first">Windows, Linux, MacOS</li>
								</ul>
								<h4>Hardware Knowledge</h4>
								<ul class="attributes">
								<li class="first">Xilink & ModelSim</li>
                                <li class="first">Industrial Interfaces: GigE, GenICam, Serial, TCP/IP</li>
                                <li class="first">Basler, Sony, UEye, The Imaging Source and many other industrial cameras</li>
                                <li class="first">Many industrial vision hardware</li>
								</ul>
							</div>
							<div class="clear"></div>
                
                <div class="col c1-1 first">
                    <h4>Teaching</h4>
                <ul class="attributes">
									<li class="first">		 	 
<h6>Assistant in Computer Vision</h6>
<h7><p>Topics: Introduction to Computer Vision, Human Visual System, Image Formation, Pointwise Image Operations, Image Intensity Transformations, Geometric/Coordinate Transforms, Interpolation, Image Neighborhood Operations, Spatial Filtering, Edge Detection, Feature Extraction, Principal Component Analysis and Applications, Morphological Image Processing, Basic Segmentation, Thresholding techniques, Motion/Dynamic Scenes, Color and texture, Object/Shape Modeling / Recognition.</p>
<p>Objective: To teach the fundamentals of computer vision, which tries to ?make computers see and interpret? using the observations in the form of multiple 2D (or 3D) images.</p></h7>
                                        </li>
                    <li class="first">		 	 
<h6>Assistant in Pattern Recognition</h6>
<h7><p>Statistical Pattern Recognition: Parameter Estimation and Supervised Learning, Bayesian Decision Theory, nonparametric approaches (Parzen windows, Nearest Neighbor), Linear Discriminant Functions, Feature extraction/selection; Pattern Recognition via Neural Networks; Syntactic Pattern Recognition; Nonmetric Methods, Unsupervised Learning and Clustering, Hidden Markov Models, Classifier Combination</p><p>Objective: To give a systematic account of the major topics in pattern recognition, with emphasis on real world applications like automated face recognition, speech recognition, DNA sequence identification</p></h7>
                                        </li>
 	 </ul>
                    <h4>Courses @ TUM</h4>
                <ul class="attributes">
									<li class="first">		 	 
<h6>Numerical Programming II (5 ECTS)</h6>
<h7><p>Advanced course on Numerical Programming. Topics covered mainly include PDEs. The topics of Numerical Programming I are covered in more detail.</p></h7>
                                        </li>
                    
                    <li class="first">		 	 
<h6>Parallel Programming (5 ECTS)	</h6>
<h7><p>This course mainly focuses on MPI and OpenMP. Throughout the semester, students implement various parallel algorithm using MPI and OpenMP. For MPI programs, supercomputer inside Garching campus @ TUM is utilized.</p></h7>
                                        </li>
 	 
 <li class="first">		 	 
<h6>Scientific Computing II</h6>
<h7><p>This course provides a deeper knowledge in two important fields of scientific computing: 
Solution of large sparse systems of linear equations: Gaussian elimination, relaxation methods, multi-grid methods, steepest descent, conjugate gradient methods
Molecular dynamics simulations: The physical model, the mathematical model, approximations and discretization, aspects of implementation, examples of nano-fluidic simulations.</p></h7>
                                        </li>
 <li class="first">		 	 
<h6>Software Engineering for Engineers	 </h6>
<h7><p></p></h7>
                                        </li>

  <li class="first">		 	 
<h6>Augmented Reality (5 ECTS)	 </h6>
<h7><p>Augmented Reality (AR) allows users to view computer information that is graphically embedded within the real three-dimensional world. Using a semi-transparent head-mounted display (HMD) attached to a wearable computer, a user can inspect and manipulate objects while viewing information about these objects in the HMD. This information is typically displayed as virtual objects in the real world, thus augmenting the perception of the user. The wearable computer enables users to carry their work as they normally do, without imposing constraints on their mobility or their hand. AR applications span from medical minimally invasive surgery to manufacturing, from machine inspection and repair to games and tourist guides. This class presents the technical foundations of Augmented Reality - as used in current international research and applications.</p></h7>
                                        </li>
         <li class="first">		 	 
<h6>Numerical Programming I (8 ECTS)	  </h6>
<h7><p>
This course provides an overview of numerical algorithms. Topics are: Floating point arithmetic, Solving Linear systems, Interpolation, Quadrature, Eigenvalue problems, Basics of iterative methods, Basics of numerical methods for ordinary differential equations.
The course will start with a short revision of mathematical foundations for numerical algorithms.</p></h7>
                                        </li>  
<li class="first">		 	 
<h6>Scientific Computing & Scientific Computing Lab (5 ECTS) </h6>
<h7><p>These courses provide an overview of scientific computing, i.e. of the different tasks to be tackled on the way towards powerful numerical simulations. The entire "pipeline" of simulation is discussed: Mathematical models: derivation, analysis, and classification, Numerical treatment of these models: discretization of (partial) differential systems, grid generation, Efficient implementation of numerical algorithms: implementation on monoprocessors vs. parallel computers (architectural features, parallel programming, load distribution, parallel numerical algorithms), Interpretation of numerical results & visualization, Validation, Numerical methods for stationary and instationary partial differential equations, Solvers for large, Sparse systems of linear equations, adaptivity and adaptively refined discretization grids, Applications from fluid dynamics and heat transfer.</p></h7>
                                        </li>  
 	 </ul>
<h4>Courses @ Sabanci University</h4>
                <ul class="attributes">
                    <li class="first">		 	 
<h6>EE 684 Advanced Computer Vision (3 Credits) </h6>
<h7><p>Special topics in telecommunications. Materials included: Camera Calibration, 3D Reconstruction, Spline Curves, Differential Geometry, and paper implementations.</p></h7>
                                        </li>  
                 <li class="first">		 	 
<h6>EE 566 Pattern Recognition (3 Credits)</h6>
<h7><p>Statistical Pattern Recognition: Parameter Estimation and Supervised Learning, Bayesian Decision Theory, nonparametric approaches (Parzen windows, Nearest Neighbor), Linear Discriminant Functions, Feature extraction/selection; Pattern Recognition via Neural Networks; Syntactic Pattern Recognition; Nonmetric Methods, Unsupervised Learning and Clustering, Hidden Markov Models, Classifier Fusion...</p></h7>
                                        </li>     
                    
                    <li class="first">		 	 
<h6>EL480 Advanced Computer Interfacing (3 Credits)</h6>
<h7><p>Special topics in electronics. My research topic was implementing a template matching algorithm on NVIDIA GPUS using CUDA libraries provided by NVIDIA. GPGPUs can compute common tasks almost 50-200 times faster than a normal CPU. Parallel computing in GPUs play a very important role in high performance computing.</p></h7>
                                        </li>  
                    
                                        <li class="first">		 	 
<h6>EE 585 Medical Image Analysis (3 Credits)</h6>
<h7><p>Special topics in Electronics. Level sets, Active Contours, Registration and medical imaging techniques are discussed and covered. Implementation homework is given.</p></h7>
                                        </li>  
										<li class="first">		 	 
<h6>TE 407 Computer Vision (4 Credits)</h6>
<h7><p>Digital image fundamentals. Elements of image processing systems. Image model and imaging geometry. Image sampling and quantization. Digital Convolution, Point Operations (image brightness modification, contrast enhancement, thresholding), Global operations (Histogram equalization), Neighborhood operations (Image smoothing, image sharpening), Geometric operations (Display adjustment, image warping, magnification and rotation), Temporal (frame based) operations, Edge Detection and Segmentation, Contours, shape modeling, Morphology, Texture analysis, Color image processing, Image Compression.</p></h7>
                                        </li>  
<li class="first">		 	 
<h6>TE 407 Computer Vision (4 Credits)</h6>
<h7><p>Digital image fundamentals. Elements of image processing systems. Image model and imaging geometry. Image sampling and quantization. Digital Convolution, Point Operations (image brightness modification, contrast enhancement, thresholding), Global operations (Histogram equalization), Neighborhood operations (Image smoothing, image sharpening), Geometric operations (Display adjustment, image warping, magnification and rotation), Temporal (frame based) operations, Edge Detection and Segmentation, Contours , shape modeling, Morphology, Texture analysis, Color image processing, Image Compression.</p></h7> </li>  

<li class="first">		 	 
<h6>CS 404 Artificial Intelligence (3 Credits)	</h6>
<h7><p>This course is a broad technical introduction to fundamental concepts and techniques in artificial intelligence. Topics include expert systems, rule based systems, knowledge representation, search, planning, managing uncertainty, machine learning, and neural networks. Important current application areas of artificial intelligence, such as computer vision, robotics, natural language understanding, and intelligent agents, will be discussed.</p></h7> </li>  
<li class="first">		 	 
<h6>TE 405 Digital Audio & Speech Processing (3 Credits)</h6>
<h7><p>Digital Speech and Audio Processing Linear Predictive modeling of Speech. Pitch Estimation Speech Modeling. Speech Coding using Linear Predictive methods: LPC-10, CELP, MELP algorithms. Speech recognition, and synthesis. Audio processing and coding, MPEG standard. </p></h7> </li>  

<li class="first">		 	 
<h6>CS 401 Computer Architectures (3 Credits)</h6>
<h7><p>This is an introductory course on computer architecture. Topics include: basics of the von Neumann machine, instruction set architecture, instruction formats addressing modes, machine language, instruction fetch, decode and execution cycle, data path and arithmetic logic unit design, arithmetic algorithms, hardwired and microprogrammed control organization, input and output organization, memory interface.</p></h7> </li>  
 
<li class="first">		 	 
<h6>EL 308 Microcomputer Based System Design (3 Credits)</h6>
<h7><p>This is an introductory course on computer architecture. Topics include: basics of the von Neumann machine, instruction set architecture, instruction formats addressing modes, machine language, instruction fetch, decode and execution cycle, data path and arithmetic logic unit design, arithmetic algorithms, hardwired and microprogrammed control organization, input and output organization, memory interface.</p></h7> </li>  
                    
<li class="first">		 	 
<h6>EL 310 Hardware Description Languages (HDL) (3 Credits)</h6>
<h7><p>Introduction to hardware description languages; VHDL fundamentals, behavioral and structural models; syntax and basic rules; design entry; behavioral simulation; logic synthesis and synthesizable code development; design mapping to standard cells and/or field programmable gate array (FPGA).</p></h7> </li>  
                    
<li class="first">		 	 
<h6>CS 408 Computer Networks (3 Credits)</h6>
<h7><p>This course is an introduction computer networks. Topics include network architectures, local and wide-area networks, network technologies and topologies; data link, network, and transport protocols, point-to-point and broadcast networks; routing, addressing, naming, multicasting, switching, internetworking congestion/flow/error control, quality of service, and network security.</p></h7> </li>  
                    
<li class="first">		 	 
<h6>CS 307 Operating Systems (3 Credits)</h6>
<h7><p>This course covers fundamental aspects of operating systems: management of resources such as CPU, memory space and peripheral devices. Topics include concurrent processes, mutual exclusion, process communication, cooperation, deadlocks, semaphores, scheduling, and protection. The course will also highlight important aspects of operating systems such as UNIX, Windows, etc.</p></h7> </li>  
                    
<li class="first">		 	 
<h6>TE 302 Discrete-Time Signals and Systems (3 Credits)	</h6>
<h7><p>Review of linear discrete-time systems and sampled and discrete-time signals; Fourier analysis, discrete and fast Fourier transforms; interpolation and decimation; design of infinite-impulse response and finite impulse response filters. Introduction to real time processing using Digital Signal Processors (DSP) chips.</p></h7> </li>  
                    
<li class="first">		 	 
<h6>MATH 306 Statistical Modeling (3 Credits)	</h6>
<h7><p>Statistical inference; estimation, confidence intervals, hypothesis testing; analysis of variance; goodness of fit tests; regression and correlation analysis; Bayesian methods; introduction to design of experiments; use of statistical software.</p></h7> </li>  
                    
<li class="first">		 	 
<h6>TE 301 Introduction to Signal Processing and Information Systems (3 Credits)	</h6>
<h7><p>Discrete-time Fourier transform. Discrete-time processing of continuous-time signals. Basic communication concepts, modulation, AM, FM, pulse amplitude modulation. Laplace transform, system response. Z-transform. Systems characterized by differential and difference equations. Control systems and feedback. Uncertainty and randomness in signals and systems.</p></h7> </li>  
                    
<li class="first">		 	 
<h6>ENS 211 Signals (3 Credits)	 </h6>
<h7><p>Continuous and discrete, periodic and aperiodic signals, impulse, unit step. The concept of signal space, inner product, norm, bases. Fourier series, bandwidth. Gibbs effect. Fourier transform. DFT. Filtering. Sampling of continuous signals, aliasing. Bandlimited reconstruction, interpolation.</p></h7> </li>  
                    
<li class="first">		 	 
<h6>EL 202 Electronic Circuits II (4 Credits)	 </h6>
<h7><p>Concepts of lumped and distributed circuits; frequency dependence of circuit characteristics; introduction to feedback circuits and feedback amplifiers; concepts of stability, phase margin and compensation; multi-stage amplifier circuits, power amplifier circuits, oscillators. Laboratory exercises are provided to reinforce the theory of operation of these circuits.</p></h7> </li>  
                    
<li class="first">		 	 
<h6>ENS 203 Electronic Circuits I (4 Credits)	 </h6>
<h7><p>Passive components, basic circuit analysis, first order circuits, transient and steady state analysis, second order RLC circuits, resonance, amplifier fundamentals, operational amplifiers, introduction to diodes and transistors. Prerequisite for EL 202.</p></h7> </li>  
                    
<li class="first">		 	 
<h6>CS 303 Logic and Digital System Design (4 Credits)	</h6>
<h7><p>Number systems and conversion, boolean algebra, the assertion level concept; minterm and maxterm expensions, Karnaugh maps,and Quine McCluskey minimization, combinatorial logic circuit design, NAND and NOR gate based design. State machines and sequential circuits flip-flops, minimization of state tables, state assignment. Higher level digital system desin using SSI-MSI blocks such multiplexers/decoders, adders, memory and programmable gate arrays; bus oriented systems. Asynchronous sequential circuits, flow tables, timing hazards.</p></h7> </li>
                    
<li class="first">		 	 
<h6>MATH 203 Introduction to Probability and Statistics (3 Credits)	</h6>
<h7><p>Experiments and events. Probability axioms. Counting techniques. Conditional probability, independent events, discrete and continuous sample spaces. Random variables and distribution function. Some standard distributions. Sampling and statistics. Also part of the "core course" pools for the BIO, TE, MS degree programs, and simultaneously one of the required courses for the FASS degree program in Economics.</p></h7> </li>
                    
<li class="first">		 	 
<h6>MATH 202 Differential Equations (3 Credits)</h6>
<h7><p>First-order differential equations and solution methods. Direction fields, qualitative methods, numerical approximations. Higher-order linear differential equations. Linear systems. Nonlinear systems, asymptotic behaviour of solutions. Laplace transform. Also part of the "core course" pools for the BIO, MAT, ME, EL, TE, MS degree programs.</p></h7> </li>
                    
<li class="first">		 	 
<h6>MATH 201 Linear Algebra (3 Credits)	 </h6>
<h7><p>Systems of linear equations; Gaussian elimination. Vector spaces, subspaces, linear, independence, dimension, change of basic. Linear transformations. Inner product, orthogonality. Eigenvalues. Diagonalization and canonical forms. Cayley-Hamilton Theorem.</p></h7> </li>
                    
<li class="first">		 	 
<h6>CS 202 Data Structures (3 Credits)</h6>
<h7><p>Introduction to theoretical aspects of computing: modeling algorithms and their run times, computational complexity. Linear data structures (lists, stacks, queues) trees (tries, binary search trees, AVL trees, tree traversals), hashing and hash tables, graphs and their representations, graph algorithms (depth first and breadth first search, single source shortest path algorithms), sorting algorithmic paradigms (divide and conquer, greedy, dynamic programming).</p></h7> </li>
                    
<li class="first">		 	 
<h6>CS 201 Introduction To Computing (3 Credits)</h6>
<h7><p>This course is intended to introduce students to the field of computing (basic computer organization, data representation, concepts, algorithmic thinking and problem solving), as well as giving them intermediate level programming abilities in an object-oriented programming language (currently C++). Also part of the "core course" pools for the CS, BIO, MAT, ME, EL, TE, MS degree programs.</p></h7> </li>
                    </ul>
                    </div>
						</div>
					</section>
					<section id="apps-page" class="content">
						<div class="inner">
							<div class="col c1">
								
                                <article>
									<div class="infoPost col c3-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-post" href="#">
												<img src="img/posts/thumb/turbine2.jpg" alt="Reconstructing Energy Turbines" title="Reconstructing Energy Turbines" />
												<div><span><i class="fa fa-plus circle"></i></span></div>
											</a></li>
										</ul>
									</div>
									<div class="introTextPost col c3-2">
										<h4>3D Reconstruction of Large Objects</h4>
										<p>A major part of my PhD work considered reconstructing very large objects easily using CAD priors. Supported by Siemens AG, the outcome is now deployed in multiple factories, used in real life to inspect turbines against their CAD models (shown on the left). I have received Young Professional Award granted by European Machine Vision Association regarding this product - please check the links on the very left for details.</p>
                                        <a href="#papp-3drec" class="readmore">Read more &rarr;</a>
									</div>
								</article>
                                <hr />
                                
                                <article>
									<div class="infoPost col c3-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-post" href="#">
												<img src="img/posts/thumb/multicam.jpg" alt="Multiple Camera Geometry" title="Multiple Camera Geometry" />
												<div><span><i class="fa fa-plus circle"></i></span></div>
											</a></li>
										</ul>
									</div>
									<div class="introTextPost col c3-2">
										<h4>Non-contact 3D Measurement for Automated %100 Inspection</h4>
										<p>As part of my external PhD work and for one of our clients, we have developed a non-contact 3D measurement machine, which automatically retrieves the large part to be measured and outputs the measurement report with a 1-1 correspondence to the old fashioned CMMs. The entire project was managed by me. Furthermore the core algorithms for 3D vision and measurement were coded solely by me. The project was a success in satisfying the sharp accuracy and precision demands of the industry.</p>
									</div>
								</article>
                                <hr />
                                
								<article>
									<div class="infoPost col c3-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-post" href="http://www.befunky.com" target="befunky">
												<img src="img/posts/thumb/befunky_logo_small.png" alt="BeFunky's small logo" title="BeFunky" />
												<div><span><i class="fa fa-plus circle"></i></span></div>
											</a></li>
										</ul>

									</div>
									<div class="introTextPost col c3-2">
										<h4>BEFUNKY!</h4>
										<p>BeFunky is an online application that allows users to recreate images/videos as digital paintings, cartoons, and comics without the need for any professional skills or having to download specific tools. The sophisticated cartoonizing algorithm lets the user create a very cartoon-like image and a detailed sketch. Also user has the option to warp the image to caricaturize more. Examples can be found on the web site, membership is free. During my bachelor studies I have taken a step to co-found this nice webpage.</p>
									</div>
								</article>
                                
                                <a href="http://www.befunky.com" class="readmore" target="befunky">befunky.com</a>
								<hr />
                                
                                <article>
									<div class="infoPost col c3-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-post" href="#">
												<img src="img/posts/thumb/fordui_small.jpg" alt="Ford User Interface" title="Ford User Interface" />
												<div><span><i class="fa fa-plus circle"></i></span></div>
											</a></li>
										</ul>

									</div>
									<div class="introTextPost col c3-2">
										<h4>Brake Disk Inspection for Automated Quality Control</h4>
										<p>This project was in collaboration with Gate Electronics, where for an important customer we have assembled a complete system, composed of 4 cameras, light units, 2 separate protection cabins. There are more than 60 classes of disks to inspect and more than 10 algorithms were involved to inspect different parts effectively, including image matching, laser profile measurement, intensity variation validations and code reading.

Other than managing this project, I was also in the role of the lead developer, playing the most fundamental part in realizing this project. </p>
									</div>
								</article>
								<hr />
                                
                                <article>
									<div class="infoPost col c3-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-post" href="#">
												<img src="img/posts/thumb/forzen_time1.jpg" alt="Frozen Time" title="Frozen Time" />
												<div><span><i class="fa fa-plus circle"></i></span></div>
											</a></li>
										</ul>
							
									</div>
									<div class="introTextPost col c3-2">
										<h4>FrozenTime : A Multicamera Framework For BulletTime Effect</h4>
										<p>FrozenTime is a novel, repeatable, compact system and architecture for capturing on the fly bullet-time (Matrix like) videos. This system involves >50 cameras to capture a flawless. This software contains:</p>

                                        <p>- Synchronous video capture</p>
                                        <p>- On the fly chrome keying</p>
                                        <p>- State of the art video stabilization</p>
                                        <p>- Video output with low disk footprint</p>


<p>This project is used in Coca Cola Advertising Tent and was one of the most interesting works. The project page, for the moment, is only in Turkish.</p>

										<a href="#papp-frozentime" class="readmore">Read more &rarr;</a>
									</div>
								</article>
								<hr />
                                
                                <article>
									<div class="infoPost col c3-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-post" href="#papp-istanbul">
												<img src="img/posts/thumb/istanbul.jpg" alt="Istanbul-o-matik" title="Istanbul-o-matik" />
												<div><span><i class="fa fa-plus circle"></i></span></div>
											</a></li>
										</ul>
																				
									</div>
									<div class="introTextPost col c3-2">
										<h4>Istanbul-o-matik, an interactive projection mapping installation</h4>
										<p>With me being the CEO, Gravi, as a team engaged in this interactive real-time mapping project to be showcased at the first Istanbul Design Biennial at Istanbul Modern Museum. The idea was to create an abstract view of Istanbul emphasizing the history, culture and future as well as the current structural problems of the city. </p>
										<a href="#papp-istanbul" class="readmore">Read more &rarr;</a>
									</div>
								</article>
								<hr />
                                <article>
									<div class="infoPost col c3-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-post" href="#papp-surfact">
												<img src="img/posts/thumb/surfact1.jpg" alt="Surfact Projection System" title="Surfact Projection Surfaces" />
												<div><span><i class="fa fa-plus circle"></i></span></div>
											</a></li>
										</ul>
										
																</div>
									<div class="introTextPost col c3-2">
										<h4>Surfact</h4>
										<p>Gravi SurfACT opens up an entirely new way to attract visitors’ and customers’ attention in organizations and events, such as concerts, exhibitions and fairs. Gravi Interactive Floors uses the projection area on the floor as a display and the users’ body movements for interaction. Without the need of any remote control or external device and with its high playability, Gravi SurfACT succeeds to be the center of interest in any place it is installed.</p>

										<a href="#papp-surfact" class="readmore">Read more &rarr;</a>
									</div>
								</article>
								<hr />
                                <article>
									<div class="infoPost col c3-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-post">
												<img src="img/posts/thumb/skeleton_small.jpg" alt="Skeleton Edges" title="Skeleton Edges" />
												<div><span><i class="fa fa-plus circle"></i></span></div>
											</a></li>
										</ul>
							
									</div>
									<div class="introTextPost col c3-2">
										<h4>Particle beam radiotherapy on GPU</h4>
										<p>Capturing CT data for the breathing simulation is not possible due to the non-real-time techniques employed in computer tomography. However, the breathing movements of patients should always be considered when developing medical imaging algorithms. As it wasn't really possible to acquire this data, under supervision of Dr. Fatih Porikli, I have developed a simulation algorithm, which generates a 4D video of breathing patient, out of a single 3D CT scan. This CUDA implementation respected the rigidness of the bones, while applying reasonable deformations to other tissues and organs. The result was an easy to use dataset and testbed for many tracking algorithms.</p>
									</div>
								</article>
                                <hr />
								<article>
									<div class="infoPost col c3-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-post">
												<img src="img/posts/thumb/robochess1.jpg" alt="Chess Playing Robot" title="Chess Playing Robot" />
												<div><span><i class="fa fa-plus circle"></i></span></div>
											</a></li>
										</ul>
									</div>
									<div class="introTextPost col c3-2">
										<h4>RoboChess: Chess Playing Robot</h4>
										<p>Robochess is a chess playing robot, which is able to play against a person. Cameras are used to locate initial and final positions of the pieces. A gripper and a 3D XYZ Cartesian robot controlled by a PLC were used to grab the pieces and position them. The chess pieces aren't specially designed, except they have a certain height. The chess engine is also developed by me. The robot is also able to connect via internet, meaning that if you have one of these you can play against a real opponent who's playing online chess in his computer while you play through RoboChess. Macromedia Flash interface is also available. RoboChess was demonstrated in ARIF 2006. The application is developed in Microsoft Visual C# 1.1, Festo PLC Program. All the core algorithms were coded in C. (Developed in 1.5 months)</p>
									</div>
								</article>
                                <hr />
								<article>
									<div class="infoPost col c3-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-post">
												<img src="img/posts/thumb/robo112.JPG" alt="Robo112 - Helper Robot" title="Helper Robot" />
												<div><span><i class="fa fa-plus circle"></i></span></div>
											</a></li>
										</ul>
									</div>
									<div class="introTextPost col c3-2">
										<h4>Robo112: Autonomous Vision Based Helper Robot</h4>
										<p>Robo112 was designed to help a crippled human being to go and grab objects, especially if the object is on the ground. It can follow his special marks and arrives at the destination point, which is previously marked. Robo112 knows the wanted object by reading text (OCR). You show some text to it, which is previously taught, and it finds the object matching to the text (which is also previously taught. Multi Layer Perceptrons were used for OCR and template matching by image pyramids was used for object matching. This robot is also capable of detecting faces and following them in pretty much varying environments. Click here to go to his web page</p>
									</div>
								</article>
								<div class="clear"></div>
							</div>
							<div class="clear"></div>
						</div>
					</section>
        
					<section id="blog-page" class="content">
						<div class="inner">
							<div class="col c1">
								                                
                                <article>
									<div class="infoPost col c3-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-post" href="#post-mvg">
												<img src="img/posts/thumb/multiview.jpg" alt="Multiple View Geometry" title="Multiple View Geometry" />
												<div><span><i class="fa fa-plus circle"></i></span></div>
											</a></li>
										</ul>
										
									</div>
									<div class="introTextPost col c3-2">
										<h4>Robust Matching of 3D CAD Models to Multiple Views</h4>
										<p>Nowadays, multi-cameras are ubiquitous in our world, because of the fact that they are able to provide much more information than a single camera does. As the camera prices decrease, people are extensively benefiting from using large amount of cameras. Many applications such as augmented reality, video surveillance, 3D reconstruction and industrial inspection already use multiple cameras. The recent research predicts that such applications will continue to utilize many cameras. Additionally, the market research shows that such a generic measuring system has a lot of use, especially in Automobile Industry, White-Goods Industry, Electronics Industry and so on. 
</p>
										<a href="#post-mvg" class="readmore">Read more &rarr;</a>
									</div>
								</article>
								<hr />
                                
                                 <article>
									<div class="infoPost col c3-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-post" href="#post-edge">
												<img src="img/posts/thumb/subpix_edge2.jpg" alt="Subpixel Edge Image" title="Subpixel Edge Image" />
												<div><span><i class="fa fa-plus circle"></i></span></div>
											</a></li>
										</ul>
										
										<p><a href="#post-1" title="Medical Image with Sub-pix Edge">The raw version of this image is taken from Siemens Magnetom Skyra.</a></p>
									</div>
									<div class="introTextPost col c3-2">
										<h4>Sub-pixel Accurate Edge Detection and Linking</h4>
										<p>Precise detection and sub-pixel edge localization is of great importance in increasing the accuracy of measurement techniques. In this project, I presented a very accurate sub-pixel localization and further linking algorithm and form a thorough framework for sub-pixel edge analysis, treating edges as connected regions and redefining linking operation as an analogous to connected component labeling. The edges are detected using a novel third order filter with a sub-pixel linking stage similar to hysteresis thresholding. However, using the classical Canny approach is not possible due to sub-pixel edge points. On the image shown on the right, the smooth sub-pixel edges are linked and painted on the image. Each connected edge piece is painted in a different color. Notice that on the junction points, the edges are correctly split.</p>
										<a href="#post-edge" class="readmore">Read more &rarr;</a>
									</div>
								</article>
								<hr />
                                
                                <article>
									<div class="infoPost col c3-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-post" href="#post-thesis">
												<img src="img/posts/thumb/surface.jpg" alt="Surfact  Projection System" title="Surfact  Projection System" />
												<div><span><i class="fa fa-plus circle"></i></span></div>
											</a></li>
										</ul>
										
									</div>
									<div class="introTextPost col c3-2">
										<h4>Recovering 3D Deformations Using RGBD Cameras</h4>
										<p>In this work, we study the problem of 3D deformable surface tracking with RGBD cameras, specifically Microsofts Kinect. In order to achieve this we introduce a fully automated framework that includes several components: automatic initialization based on segmentation of the object of interest, then robust range flow that guides deformations of the object of interest and finally representation of the results using mass-spring model. The key contribution is extension of the range flow work of Spies and Jahne [1] that combines Lucas-Kanade [2] and Horn and Shunk [3] approaches for RGB-D data, makes it to converge faster and incorporates color information with multichannel formulation. We also introduced a pipeline for generating synthetic data and performed error analysis and comparison to original range flow approach. The results show that our method is accurate and precise enough to track significant deformation smoothly at near real-time run times.
</p>
										<a href="#post-thesis" class="readmore">Read more &rarr;</a>
									</div>
								</article>
								<hr />
                                
                                <article>
									<div class="infoPost col c3-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-post" href="#post-matching">
												<img src="img/posts/thumb/matching1.jpg" alt="Image Matching Algorithm" title="Template Matching" />
												<div><span><i class="fa fa-plus circle"></i></span></div>
											</a></li>
										</ul>
										

									</div>
									<div class="introTextPost col c3-2">
										<h4>Real-time Illumination, Clutter and Occlusion Invariant Shape Matching</h4>
										As vision moves towards more semantic and tougher problems, low-level vision still suffers from unpaid attention. Academia begins to take those low level problems such as template matching for granted, however when the moment comes to choose a method, which really works, most methods become unsatisfactory. At this point, it is not hard to observe that despite the recent advancements in template matching techniques, the final word on rotation and scale invariant matching under unpredictable illumination conditions and significant occlusion is still not said. While feature based methods seem to provide effective tools, meeting the real-time constraints require undesired tricks for optimization. In this work, our aim is to take a well-known 2D robust shape matching framework and refactor it so well that it would undoubtedly satisfy the runtime restrictions.
										<a href="#post-matching" class="readmore">Read more &rarr;</a>
									</div>
								</article>
								 <hr />
                                 <article>
									<div class="infoPost col c3-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-post" href="#post-ar">
												<img src="img/posts/thumb/ar_track.jpg" alt="Augmented Reality Tracking" title="Augmented Reality Tracking" />
												<div><span><i class="fa fa-plus circle"></i></span></div>
											</a></li>
										</ul>
										
										
									</div>
									<div class="introTextPost col c3-2">
										<h4>Real-time Detection and Tracking Framework for Augmented Reality</h4>
										<p>Even though many feature based techniques exist for localizing and tracking planar (and even non-planar) templates, it is still a question of wonder on how to implement a proper algorithm, which could really detect and track templates, under perspective deformations, illuminations changes and in clutter, with rotation invariance. In this work we uncover this mystery and provide insights and experimentation on implementing a really real-time, robust AR base.</p>
										<a href="#post-ar" class="readmore">Read more &rarr;</a>
									</div>
								</article>
								<hr />
                                <article>
									<div class="infoPost col c3-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-post" href="#post-hmm">
												<img src="img/posts/thumb/barcode.jpg" alt="Barcode Decoding Demo" title="Barcode Image" />
												<div><span><i class="fa fa-plus circle"></i></span></div>
											</a></li>
										</ul>
										
									</div>
									<div class="introTextPost col c3-2">
										<h4>A Hierarchical HMM for Reading Challenging Barcodes</h4>
										<p>In state of the art manufacturing processes, barcode labeling is a ubiquitous method to track products and goods. Thus, it is of great importance to have a powerful machinery of decoding them, even under severe deformations, damages, blur, occlusion and bad illumination conditions. The applications are numerous. From assisting blind people to industrial automated inspection, technology demands solid barcode reading algorithms. Yet, to the best of our knowledge, no existing well-established framework exists to accomplish this task. In this work, we propose an algorithm for real-time decoding of barcodes, with state of the art accuracy. Our method is based on a very well-studied hierarchical HMM framework and the decoding process is posed as a Viterbi dynamic programming, which allows us to use pruning strategies to search a large state space in real-time.</p>
										<a href="#post-hmm" class="readmore">Read more &rarr;</a>
									</div>
								</article>
								<hr />
                               <article>
									<div class="infoPost col c3-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-post" href="#post-rw">
												<img src="img/posts/thumb/random_walk.jpg" alt="Random Walks Image" title="Random Walker Image" />
												<div><span><i class="fa fa-plus circle"></i></span></div>
											</a></li>
										</ul>
									</div>
									<div class="introTextPost col c3-2">
										<h4>Efficient Random Walks in C</h4>
										<p>I implemented a soft-real-time implementation of the famous Random Walks tracking algorithm in Ansi C taking advantage of sparse computations. The result was used in tracking ultrasound images smoothly and efficiently. A nice OpenGL based video processing GUI in QT was complementary.</p>
										<a href="#post-rw" class="readmore">Read more &rarr;</a>
									</div>
								</article>
                                <hr />
								<article>
									<div class="infoPost col c3-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-post" href="#post-bilateral">
												<img src="img/posts/thumb/bilateral2.jpg" alt="Bilateral Filtering" title="Bilateral Filtering" />
												<div><span><i class="fa fa-plus circle"></i></span></div>
											</a></li>
										</ul>
							
									</div>
									<div class="introTextPost col c3-2">
										<h4>Constant Time O(1) Bilateral Filtering</h4>
										<p>At MERL, Dr. Fatih Porikli has developed an algorithm for constant time bilateral filtering of images. When implemented on GPU using CUDA there was an improvement of 25 folds, compared to a somehow optimized OpenMP implementation. The details of the implemented algorithm are presented in this paper:</p><p><a href="http://www.merl.com/reports/docs/TR2008-030.pdf" target="bilateral_filter_paper">Constant Time O(1) Bilateral Filtering
</a></p><p></p>
										<a href="#post-bilateral" class="readmore">Read more &rarr;</a>
									</div>
								</article>
								<hr />
                                 <article>
									<div class="infoPost col c3-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-post" href="#post-greenbox">
												<img src="img/posts/thumb/greenbox.jpg" alt="Greenbox Image Processing" title="Greenbox Cutout" />
												<div><span><i class="fa fa-plus circle"></i></span></div>
											</a></li>
										</ul>
										
									</div>
									<div class="introTextPost col c3-2">
										<h4>An Algorithm for Efficient Chroma Keying</h4>
										<p>Project FrozenTime required a significantly robust and fast green-box chroma keying algorithm, more advanced than current propositions. Utilizing Inverse Covariance - Khachiyan's Ellipsoid relations, this algorithms turned out to be very feasible.</p>
										<a href="#post-greenbox" class="readmore">Read more &rarr;</a>
									</div>
								</article>
                                <hr />
								<article>
									<div class="infoPost col c3-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-post" href="#post-2">
												<img src="img/posts/thumb/reco4D.jpg" alt="4D Reconstruction" title="4D Reconstruction" />
												<div><span><i class="fa fa-plus circle"></i></span></div>
											</a></li>
										</ul>
				
									</div>
									<div class="introTextPost col c3-2">
										<h4>Workflow Analysis Using 4D Reconstruction Data</h4>
										<p>This project targets the workflow analysis of an interventional room equipped with 16 cameras fixed on the ceiling. It uses real-time 3D reconstruction data and information from other available sensors to recognize objects, persons and actions. This provides complementary information to specific procedure analysis for the development of intelligent and context-aware support systems in surgical environments.</p>
									</div>
								</article>
								<a href="http://campar.in.tum.de/Chair/ProjectWorkflow4D" class="readmore" target="workflow4d">TUM Project Webpage</a>
								<hr />
<article>
									<div class="infoPost col c3-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-post" href="#post-1">
												<img src="img/posts/thumb/templatevideo.jpg" alt="Template Matching Video" title="Template Matching Video" />
												<div><span><i class="fa fa-plus circle"></i></span></div>
											</a></li>
										</ul>
							
									</div>
									<div class="introTextPost col c3-2">
										<h4>Spatio Temporal Shape Matching</h4>
										<p>Under supervision of Dr. Yan Ke and Prof. Martial Hebert, I have worked on the project of reconstructing spatio-temporal shapes to be used in conjunction with action recognition.</p>
										
									</div>
								</article>
								<article>
									<div class="infoPost col c3-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-post">
												
												<div></div>
											</a></li>
										</ul>
										
									</div>
								</article>
                                
                            <div class="clear"></div>
							</div>
							<div class="clear"></div>
						</div>
					</section>
					<section id="post-mvg-page" class="content">
						<div class="inner">
							<div class="col c1">
								<article class="postPage">
									<h4>Robust Matching of 3D CAD Models to Multiple Views</h4>
									<img src="img/posts/multiview.jpg" alt="Multiple View Geometry" title="Multiple View Geometry" class="postImg" />
									<p class="caps">Nowadays, multi-cameras are ubiquitous in our world, because of the fact that they are able to provide much more information than a single camera does. As the camera prices decrease, people are extensively benefiting from using large amount of cameras. Many applications such as augmented reality, video surveillance, 3D reconstruction and industrial inspection already use multiple cameras. The recent research predicts that such applications will continue to utilize many cameras. Additionally, the market research shows that such a generic measuring system has a lot of use, especially in Automobile Industry, White-Goods Industry, Electronics Industry and so on. <p>
One of the biggest problems involved in using multi-camera setups is robust 3D measurement of CAD parts, where environment and process dependent noise is significant. Such systems require projective registration of a CAD model to multiview camera images. Until now, many studies are carried out in order to achieve the task of fitting CAD models to multiple, monochrome photographs. In this work, we will be posing this problem as an ICP-like optimization where the global geometric poses of the individual cad parts are refined from an automatically chosen initial guess. We make use of accurate sub-pixel edges and robust functions in order to be resilient to outliers and corrupted observations. While being straightforward this method greatly enjoys from the fact that the methods used are well-studied and proven to work well under many conditions. Our approach is invariant to the structure of the geometry and sufficiently immune to errors in the initialization. While being extendible and easy to apply, this technique inherently computes the correspondences of the CAD model to the sub-pixel edges, which might further be exploited for recalibration of the measurement system not from a predefined grid, but automatically from an erroneous measurement sample.</p><p>
Eventually, we perform extensive tests on real data and demonstrate both numerically and visually that the accuracy of the system is even on a globally calibrated and inaccurate system is reasonable for the industrial standards. Last but not least, we discuss the opportunities in this field and how the current measurement systems can be improved to reach the most accurate measurements. </p>
<p>This work is not yet published, but a paper will be available soon. </p>
    

                                    <p> Below is a sample video:</p><p></p>
<iframe width="640" height="360" src="//www.youtube.com/embed/E9e7OxMmw9Q?feature=player_embedded" frameborder="0" allowfullscreen></iframe>                                   
					<p>    Click <a href="http://goo.gl/Vs2s6" target="cad_fit1"><strong>here</strong></a> for better resolution.</p>
                                    
<p>    Click <a href="downloads/gss-poster.pdf" target="cad_fit_poster"><strong>here</strong></a> for the informal poster of an early stage version .</p><p></p>
									<div class="col c1-1 first">
										<div class="info">
															
											
										</div>
									</div>
									<div class="col c1-1">
										<a href="#post-edge" class="readmore nomargintop">&rarr;</a>
										<a href="#" class="readmore nomargintop">&larr;</a>
										<a href="#blog" class="readmore nomargintop">&larr; All Posts</a>
									</div>
									<div class="clear"></div>
								</article>
							</div>
							<div class="clear"></div>
						</div>
					</section>
					<section id="post-edge-page" class="content">
						<div class="inner">
							<div class="col c1">
								<article class="postPage">
									<h4>Accurate Sub-pixel Edge Detection and Linking</h4>
									<img src="img/posts/subpix_edge3.jpg" alt="Subpixel Edges" class="postImg" title="Subpixel Edges"/>
									<p class="caps">
                                        Precise detection and sub-pixel edge localization is of great importance in increasing the accuracy of measurement techniques. In this project, I presented a very accurate sub-pixel localization and further linking algorithm and form a thorough framework for sub-pixel edge analysis, treating edges as connected regions and redefining linking operation as an analogous to connected component labeling. The edges are detected using a novel third order filter with a sub-pixel linking stage similar to hysteresis thresholding. However, using the classical Canny approach is not possible due to sub-pixel edge points.<p></p>
									<div class="col c1-1 first">
										<div class="info">
											<p>
											</p>
											
										</div>
									</div>
									<div class="col c1-1">
										<a href="#post-thesis" class="readmore nomargintop">&rarr;</a>
										<a href="#post-mvg" class="readmore nomargintop">&larr;</a>
										<a href="#blog" class="readmore nomargintop">&larr; All Posts</a>
									</div>
									<div class="clear"></div>
								</article>
							</div>
							<div class="clear"></div>
						</div>
					</section>
					<section id="post-matching-page" class="content">
						<div class="inner">
							<div class="col c1">
								<article class="postPage">
									<h4>Real-time Illumination, Clutter and Occlusion Invariant Shape Matching</h4>
									<img src="img/posts/match.jpg" alt="Template Matching Algorithm" class="postImg" title="Template Matching Algorithm"/>
									<p class="caps">As vision moves towards more semantic and tougher problems, low-level vision still suffers from unpaid attention. Academia begins to take those low level problems such as template matching for granted, however when the moment comes to choose a method, which really works, most methods become unsatisfactory. At this point, it is not hard to observe that despite the recent advancements in template matching techniques, the final word on rotation and scale invariant matching under unpredictable illumination conditions and significant occlusion is still not said. While feature based methods seem to provide effective tools, meeting the real-time constraints require undesired tricks for optimization. In this work, our aim is to take a well-known 2D robust shape matching framework and refactor it so well that it would undoubtedly satisfy the runtime restrictions.<p>To do so, the choice of matching technique plays a very important role. Hough based approaches provide certain robustness, yet when rotation space search comes into account, the memory and computation requirements increase exponentially. From thereon, we re-attack the problem of conventional template matching (searching over the spatial domain) and introduce novel ideas to make matching metrics surprisingly appealing.</p><p></p>

									
									<div class="col c2-1 first">
										<div class="info">
											<p>
											</p>
											
											
										</div>
									</div>
									<div class="col c1-1">
										<a href="#post-ar" class="readmore nomargintop">&rarr;</a>
										<a href="#post-thesis" class="readmore nomargintop">&larr;</a>
										<a href="#blog" class="readmore nomargintop">&larr; All Posts</a>
									</div>
									<div class="clear"></div>
								</article>
							</div>
							<div class="clear"></div>
						</div>
					</section>
					<section id="post-hmm-page" class="content">
						<div class="inner">
							<div class="col c1">
								<article class="postPage">
									<h4>HMM Real-time Illumination, Clutter and Occlusion Invariant Shape Matching</h4>
									<img src="img/posts/barcode.jpg" alt="Barcode Decoding" class="postImg" title="Barcode Decoding"/>
									<p class="caps">In state of the art manufacturing processes, barcode labeling is a ubiquitous method to track products and goods. Thus, it is of great importance to have a powerful machinery of decoding them, even under severe deformations, damages, blur, occlusion and bad illumination conditions. The applications are numerous. From assisting blind people to industrial automated inspection, technology demands solid barcode reading algorithms. Yet, to the best of our knowledge, no existing well-established framework exists to accomplish this task. In this work, we propose an algorithm for real-time decoding of barcodes, with state of the art accuracy. Our method is based on a very well-studied hierarchical HMM framework and the decoding process is posed as a Viterbi dynamic programming, which allows us to use pruning strategies to search a large state space in real-time.<p></p>

									
									<div class="col c2-1 first">
										<div class="info">
											<p>
											</p>
											
											
										</div>
									</div>
									<div class="col c1-1">
										<a href="#post-rw" class="readmore nomargintop">&rarr;</a>
										<a href="#post-ar" class="readmore nomargintop ">&larr;</a>
										<a href="#blog" class="readmore nomargintop">&larr; All Posts</a>
									</div>
									<div class="clear"></div>
								</article>
							</div>
							<div class="clear"></div>
						</div>
					</section>
					<section id="post-ar-page" class="content">
						<div class="inner">
							<div class="col c1">
								<article class="postPage">
									<h4>Real-time Detection and Tracking Framework for Augmented Reality</h4>
									<img src="img/posts/ar_track_samples.jpg" alt="Tracking for Augmented Reality" class="postImg" title="Tracking for Augmented Reality"/>
									<p class="caps">
                                        
Even though many feature based techniques exist for localizing and tracking planar (and even non-planar) templates, it is still a question of wonder on how to implement a proper algorithm, which could really detect and track templates, under perspective deformations, illuminations changes and in clutter, with rotation invariance. In this work we uncover this mystery and provide insights and experimentation on implementing a really real-time, robust AR base.
                                        
Our AR framework, developed mainly by myself in Gravi Labs enjoys from a reliable tracking. The current work is in fusing this AR framework with Oculus, for an amazing mixed reality experience.
                                        
Here are some techniques, which are used jointly in our framework, to achieve such robustness and speed (10ms/frame):

<p>- Real-time camera pose estimation</p>
<p>- Scale Invariant Agast feature points</p>
<p>- Threaded environment for context switching between tracking and detection</p>
<p></p>
                                    
                                    
                                    <iframe width="640" height="360" src="//www.youtube.com/embed/rZWu4LxmsME?feature=player_embedded" frameborder="0" allowfullscreen></iframe>                                    
<p>Click <a href="http://goo.gl/6VuUH2" target="ar_video"><strong>here</strong></a> for better resolution.</p>

									
									<div class="col c2-1 first">
										<div class="info">
											<p>
												
											</p>
											
										</div>
									</div>
									<div class="col c1-1">
										<a href="#post-hmm" class="readmore nomargintop">&rarr;</a>
										<a href="#post-matching" class="readmore nomargintop">&larr;</a>
										<a href="#blog" class="readmore nomargintop">&larr; All Posts</a>
									</div>
									<div class="clear"></div>
								</article>
							</div>
							<div class="clear"></div>
						</div>
					</section>
					<section id="post-thesis-page" class="content">
						<div class="inner">
							<div class="col c1">
								<article class="postPage">
									<h4>Recovering 3D Deformations Using RGBD Cameras</h4>
									<img src="img/posts/rgbd.jpg" alt="Deformable Surface Recovery" class="postImg" title="Deformable Surface Recovery"/>
									<p class="caps">Deformable surfaces are ubiquitous in real world and thus are of great interest to computer vision researchers. They exist in various forms such as packets, flags, clothing, organs, bodies and etc. For this reason, their application areas are extensive ranging from sports to entertainment, from medical imaging to machine vision. While the research in the area is quite new, many advanced methods are already being developed. Most of these methods rely on stereo computations or try to solve the under-constrained problem of recovering deformations from monocular scenes. Recently, there have been an increasing number of depth (RGBD) cameras available at commodity prices. These cameras can usually capture both color and depth images in real-time, with limited resolution and accuracy. <br>
In this thesis, we study the problem of 3D deformable surface reconstruction with such RGBD cameras. Specifically, we base our implementation on Microsoft’s Kinect. Our method can handle the global and significant deformations. We deliver our novel method as an easy tool for learning deformations, material invariant tracking and naturally a generic algorithm for 3D deformation recovery.<br>
The contribution of this thesis is three-fold. We start by proposing a new but straightforward algorithm for automatically segmenting a surface of interest from RGB-D data, which we use to initialize our tracker. Next, we take an existing surface flow framework called range flow, then improve and adapt it for our case of 3D deformation capture. This step is nothing but a surface-flow tracker. Finally, to make this tracker more robust against noise, we propose a mass spring model based post filter. The post processing step acts as a model based constraint, which attracts the individual vertices together to form an inextensible tracking capability. Our post filter is chosen to be
a cloth model, which is very well-studied in the realm of computer graphics. Last but not least, we thoroughly discuss the results and how the system behaves. The algorithm performs soft-real-time when implemented on a CPU. We also explain the parallelization aspects while paving the way for a real-time implementation on the GPU. Overall, we present a fundamental system for 3D tracking of deformable surfaces. As well as being
extendible, we show that there is also room for various improvements and advancements.
<p><a href="downloads/tolga-birdal-master-thesis.pdf" class="readmore" target="thesis-pdf">My Master Thesis &rarr;</a></p>		<p></p>							
									<div class="col c2-1 first">
										<div class="info">
											<p>
												</p>
										</div>
									</div>
									<div class="col c1-1">
										<a href="#post-matching" class="readmore nomargintop">&rarr;</a>
										<a href="#post-edge" class="readmore nomargintop">&larr;</a>
										<a href="#blog" class="readmore nomargintop">&larr; All Posts</a>
									</div>
									<div class="clear"></div>
								</article>
							</div>
							<div class="clear"></div>
						</div>
					</section>
					<section id="post-bilateral-page" class="content">
						<div class="inner">
							<div class="col c1">
								<article class="postPage">
									<h4>Constant Time O(1) Bilateral Filtering</h4>
									<img src="img/posts/bilateral.jpg" alt="Constant Time O(1) Bilateral Filtering" class="postImg" title="Constant Time O(1) Bilateral Filtering"/>
									<p class="caps">
                                        Dr. Fatih Porikli's work on bilateral filtering presented three novel methods that enable bilateral filtering in constant time O(1) without sampling. Constant time means that the computation time of the filtering remains same even if the filter size becomes very large. The first method takes advantage of the integral histograms to avoid the redundant operations for bilateral filters with box spatial and arbitrary range kernels. For bilateral filters constructed by polynomial range and arbitrary spatial filters, our second method provides a direct formulation by using linear filters of image powers without any approximations. Lastly, it is shown that Gaussian range and arbitrary spatial bilateral filters can be expressed by Taylor series as linear filter decompositions without any noticeable degradation of filter response. All these methods drastically decrease the computational time by cutting it down constant times (e.g. to 0.06 seconds per 1MB image) while achieving very high PSNR’s over 45dB. In addition to the computational advantages, those methods are straightforward to implement.                                         
At MERL, I implemented this work on GPU using CUDA there was an improvement of 25 folds, compared to a somehow optimized OpenMP implementation. The details of the implemented algorithm are presented in this paper:</p><p><a href="http://www.merl.com/reports/docs/TR2008-030.pdf" target="bilateral_filter_paper">Constant Time O(1) Bilateral Filtering
</a></p><p></p>

									
									<div class="col c2-1 first">
										<div class="info">
										</div>
									</div>
									<div class="col c1-1">
										<a href="#post-greenbox" class="readmore nomargintop">&rarr;</a>
										<a href="#post-rw" class="readmore nomargintop">&larr;</a>
										<a href="#blog" class="readmore nomargintop">&larr; All Posts</a>
									</div>
									<div class="clear"></div>
								</article>
							</div>
							<div class="clear"></div>
						</div>
					</section>
        <section id="post-rw-page" class="content">
						<div class="inner">
							<div class="col c1">
								<article class="postPage">
									<h4>Real-time Random Walks Image Segmentation</h4>
									<img src="img/posts/random_walk.jpg" alt="Random Walks Algorithm" class="postImg" title="Random Walks" />
									<p class="caps">
                                        Quoting Leo Grady, "A novel method is proposed for performing multi-label, interactive image segmentation. Given a small number
of pixels with user-defined (or pre-defined) labels, one can
analytically and quickly determine the probability that a random
walker starting at each unlabeled pixel will first reach one of
the pre-labeled pixels. By assigning each pixel to the label for
which the greatest probability is calculated, a high-quality image
segmentation may be obtained. Theoretical properties of this
algorithm are developed along with the corresponding connections to discrete potential theory and electrical circuits. This
algorithm is formulated in discrete space (i.e., on a graph) using
combinatorial analogues of standard operators and principles
from continuous potential theory, allowing it to be applied in
arbitrary dimension on arbitrary graphs." </p>
                                    <p>
                                        Due to GPGPU programming and optimized C code, I have managed to implement and run Random Walks algorithm in real-time. The video below demonstrates the initial results of the implementation.
                                    </p>
                                    <p></p>
                                    <iframe width="640" height="360" src="//www.youtube.com/embed/LXnqfDa5Fc8?feature=player_embedded" frameborder="0" allowfullscreen></iframe>
                                    <p>
                                    For more information please check 
                                    <a href="http://webdocs.cs.ualberta.ca/~nray1/CMPUT615/MRF/grady2006random.pdf" target="rw_paper">Random Walks paper of Leo Grady
</a>.</p>
									<div class="clear"></div>
									<div class="col c1-1 first">
										<div class="info">
										</div>
									</div>
									<div class="col c1-1">
										<a href="#post-bilateral" class="readmore nomargintop">&rarr;</a>
										<a href="#post-hmm" class="readmore nomargintop">&larr;</a>
										<a href="#blog" class="readmore nomargintop">&larr; All Posts</a>
									</div>
									<div class="clear"></div>
								</article>
							</div>
							<div class="clear"></div>
						</div>
					</section>
        <section id="post-greenbox-page" class="content">
						<div class="inner">
							<div class="col c1">
								<article class="postPage">
									<h4>Chroma Keying Algorithm</h4>
									<img src="img/posts/greenbox.jpg" alt="Greenbox Effect" class="postImg" />
									<p class="caps">
                                        Project FrozenTime required a significantly robust and fast green-box chroma keying algorithm, more advanced than current propositions. Utilizing Inverse Covariance - Khachiyan's Ellipsoid relations, these algorithms turned out to be very feasible.</p>
    
                                    <p> Below is a demonstration video:</p><p></p>
                                                                        <iframe width="640" height="360" src="//www.youtube.com/embed/fInDrWk_zUw?feature=player_embedded" frameborder="0" allowfullscreen></iframe>
									<div class="col c1-1 first">
										<div class="info">
										</div>
									</div>
									<div class="col c1-1">
										<a href="#post-bilateral" class="readmore nomargintop">&larr;</a>
										<a href="#blog" class="readmore nomargintop">&larr; All Posts</a>
									</div>
									<div class="clear"></div>
								</article>
							</div>
							<div class="clear"></div>
						</div>
					</section>
					<section id="papp-surfact-page" class="content">
						<div class="inner">
							<div class="col c1">
								<article class="postPage">
									<h4>Interactive Projection Floors</h4>
									<img src="img/posts/surfact.jpg" alt="Surfact Projection Surfaces" title="Surfact Projection Surfaces" class="postImg" />
									<p class="caps">
                                        Gravi SurfACT opens up an entirely new way to attract visitors’ and customers’ attention in organizations and events, such as concerts, exhibitions, fairs. Gravi Interactive Floors uses the projection area on the floor as a display and the users’ body movements for interaction. Without the need of any remote control or external device and with its high playability, Gravi SurfACT succeeds to be the center of interest in any place it is installed.
                                        <p>
The customizable infrastructure originating from Gravi’s unique technology accompanies the sensitive game controls and realistic graphics.
With score based games such as Balloon Shoot, Penalty, Exploding Bricks, Air Hockey, Football and Billiards, your visitors can enjoy the joyful atmosphere you created for them. The difficulty levels are adjustable.
With unlimited interactions capability and visual effects, you can attract all the attention, especially when the flow of visits and the transition are high. Up to now, we have developed 14 interactive effects and we can endlessly customize them to fully cover your marketing, publicity and promotion needs. </p>
    
                                    <p> Below is a sample video from runtime:</p><p></p>
                                                                        <iframe width="640" height="360" src="//www.youtube.com/embed/dI7OaSRyfD4?feature=player_embedded" frameborder="0" allowfullscreen></iframe>
                                    
									<div class="col c2-1 first">
										<div class="info">
										</div>
									</div>
									<div class="col c1-1">
										
										<a href="#papp-istanbul" class="readmore nomargintop">&larr;</a>
										<a href="#apps" class="readmore nomargintop">&larr; All Posts</a>
									</div>
									<div class="clear"></div>
								</article>
							</div>
							<div class="clear"></div>
						</div>
					</section>
					<section id="papp-istanbul-page" class="content">
						<div class="inner">
							<div class="col c1">
								<article class="postPage">
									<h4>Istanbul-o-matik, an interactive projection mapping installation</h4>
									<img src="img/posts/istanbulomatik.JPG" alt="Istanbul-o-matik" class="postImg" />
									<p class="caps">With me being the CEO, Gravi, as a team engaged in this interactive real-time mapping project to be showcased at the first Istanbul Design Biennial at Istanbul Modern Museum. The idea was to create an abstract view of Istanbul emphasizing the history, culture and future as well as the current structural problems of the city. We also wanted the user to create her own experience through some interaction. The design team worked over two months, photographing the city and animating the images using motion graphics approach. The design team's output was 100.000 texture fragments. Rendering these randomly accessible textures (because of the interaction), and composing a scene through blending and projection in real-time proved to be a challenge. The biggest task was handling I/O operations between 'disk and memory' and 'CPU and GPU'. Our team has harnessed the power of CPUs and GPUs jointly to achieve the real-time rendering. The generated content was projected on a 4.5x6m 3D maquette using high quality projectors. Yet this brings up the task of precise scene-projector calibration, which was difficult due to such immersive scale. Our proprietary scene-camera-projector calibration algorithms and interfaces, which involve me in the core of the development process, enabled us to solve this problem effectively, to the every bit of the pixel on the screen.

In the end the visualization was controlled by nine different interactions to create a specialized view combining the interactions of multiple participants in the room. The installation was very well received by critics and featured in national media. Please check the website for further info.</p>
									
									<div class="col c2-1 first">
										<div class="info">
										</div>
									</div>
									<div class="col c1-1">
										<a href="#papp-surfact" class="readmore nomargintop">&rarr;</a>
										<a href="#papp-frozentime" class="readmore nomargintop">&larr;</a>
										<a href="#apps" class="readmore nomargintop">&larr; All Posts</a>
									</div>
									<div class="clear"></div>
								</article>
							</div>
							<div class="clear"></div>
						</div>
					</section>
					<section id="papp-frozentime-page" class="content">
						<div class="inner">
							<div class="col c1">
								<article class="postPage">
									<h4>FrozenTime</h4>
									<img src="img/posts/frozentime.jpg" alt="Frozen-Time Effect" title="Bullet Time Effect" class="postImg" />
									<p class="caps">
                                        FrozenTime is a novel, repeatable, compact system and architecture for capturing on the fly bullet-time (Matrix like) videos. This system involves >50 cameras to capture a flawless. This software contains:</p><p></p>

                                    <p>- Synchronous video capture</p>
                                    <p>- On the fly chrome keying</p>
                                    <p>- State of the art video stabilization</p>
                                    <p>- Video output with low disk footprint</p>

                                   <p> For more information on how Frozen-Time is shot, you might want to check <a href="http://en.wikipedia.org/wiki/Bullet_time" target="wiki_frozentime">this Wikipedia page</a>.

This project is used in Coca Cola Advertising Tent and was one of the most interesting works. The project page, for the moment, is only in Turkish.</p>
    
                                    <p> Below is an introductory video:</p><p></p>
                                                                        <iframe width="640" height="360" src="//www.youtube.com/embed/U2ZK5GLROpk?feature=player_embedded" frameborder="0" allowfullscreen></iframe>
                                    
									
									<div class="col c2-1 first">
										<div class="info">
										</div>
									</div>
									<div class="col c1-1">
										<a href="#papp-istanbul" class="readmore nomargintop">&rarr;</a>
										<a href="#apps" class="readmore nomargintop">&larr; All Posts</a>
									</div>
									<div class="clear"></div>
								</article>
							</div>
							<div class="clear"></div>
						</div>
					</section>
					<section id="publications-page" class="content">
						<div class="inner">
							<div class="col c1-1 first">
								<h4>Selected Publications</h4>
								<ul class="attributes">
                                    
                                    <div class="infoPost col c2-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-pub">
                                                <img src="img/pub/ambiguity.JPG" alt="Ambiguity in Pose Estimation" title="Ambiguity in Pose Estimation" />
											</a></li>
										</ul>
									</div>
                                    
                                    <li class="first">
										<h5>Explaining the Ambiguity of Object Detection and 6D Pose from Visual Data<span class="period"></span></h5>
                                        <p><strong> ICCV 2019</strong>: IEEE International Conference on Computer Vision, Seoul, Korea, 2019</p>
										<h6><i class="fa fa-user"></i>Fabian Manhardt, Diego Martin Arroyo, Christian Rupprecht, Benjamin Busam, Tolga Birdal, Nassir Navab and Federico Tombari</h6>
                                        <p>3D object detection and pose estimation from a single image are two inherently ambiguous problems. Oftentimes, objects appear similar from different viewpoints due to shape symmetries, occlusion and repetitive textures. This ambiguity in both detection and pose estimation means that an object instance can be perfectly described by several different poses and even classes. In this work we propose to explicitly deal with this uncertainty. For each object instance we predict multiple pose and class outcomes to estimate the specific pose distribution generated by symmetries and repetitive textures. The distribution collapses to a single outcome when the visual appearance uniquely identifies just one valid pose. We show the benefits of our approach which provides not only a better explanation for pose ambiguity, but also a higher accuracy in terms of pose estimation.</p>
                                        <p><a href="https://arxiv.org/pdf/1812.00287.pdf" target="iccv-2019-explaining"><b><h6><font color="#C45906" size="3">Article in PDF</font></h6></b></a></p>
									</li>   
                                    
                                    <div class="infoPost col c2-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-pub">
                                                <img src="img/pub/permsync.JPG" alt="Permutation Synchronization" title="Permutation Synchronization: Birkhoff-RLMC" />
											</a></li>
										</ul>
									</div>
                                    
                                    <li class="first">
										<h5>Probabilistic Permutation Synchronization using the Riemannian Structure of the Birkhoff Polytope<span class="period"></span></h5>
                                        <p><strong> CVPR 2019</strong>: IEEE Conference on Computer Vision and Pattern Recognition, Long Beach, USA, 2019</p>
										<h6><i class="fa fa-user"></i>Tolga Birdal and Umut Şimşekli</h6>
                                        <p>We present an entirely new geometric and probabilistic approach to synchronization of correspondences across multiple sets of objects or images. In particular, we present two algorithms:(1) Birkhoff-Riemannian L-BFGS for optimizing the relaxed version of the combinatorially intractable cycle consistency loss in a principled manner,(2) Birkhoff-Riemannian Langevin Monte Carlo for generating samples on the Birkhoff Polytope and estimating the confidence of the found solutions. To this end, we first introduce the very recently developed Riemannian geometry of the Birkhoff Polytope. Next, we introduce a new probabilistic synchronization model in the form of a Markov Random Field (MRF). Finally, based on the first order retraction operators, we formulate our problem as simulating a stochastic differential equation and devise new integrators. We show on both synthetic and real datasets that we achieve high quality multi-graph matching results with faster convergence and reliable confidence/uncertainty estimates.</p>
                                        <p><a href="https://arxiv.org/pdf/1904.05814.pdf" target="cvpr-2019-probabilistic"><b><h6><font color="#C45906" size="3">Article in PDF</font></h6></b></a></p>
									</li>                         
                                    <div class="infoPost col c2-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-pub">
                                                <img src="img/pub/3dfeat.JPG" alt="3D Local Features" title="3D Local Features for Direct Registration" />
											</a></li>
										</ul>
									</div>
                                    
                                    <li class="first">
										<h5>3D Local Features for Direct Pairwise Registration<span class="period"></span></h5>
                                        <p><strong> CVPR 2019</strong>: IEEE Conference on Computer Vision and Pattern Recognition, Long Beach, USA, 2019</p>
										<h6><i class="fa fa-user"></i>Haowen Deng, Tolga Birdal and Slobodan Ilic</h6>
                                        <p>We present a novel, data driven approach for solving the problem of registration of two point cloud scans. Our approach is direct in the sense that a single pair of corresponding local patches already provides the necessary transformation cue for the global registration. To achieve that, we first endow the state of the art PPF-FoldNet auto-encoder (AE) with a pose-variant sibling, where the discrepancy between the two leads to pose-specific descriptors. Based upon this, we introduce RelativeNet, a relative pose estimation network to assign correspondence-specific orientations to the keypoints, eliminating any local reference frame computations. Finally, we devise a simple yet effective hypothesize-and-verify algorithm to quickly use the predictions and align two point sets. Our extensive quantitative and qualitative experiments suggests that our approach outperforms the state of the art in challenging real datasets of pairwise registration and that augmenting the keypoints with local pose information leads to better generalization and a dramatic speed-up.</p>
                                        <p><a href="https://arxiv.org/pdf/1904.04281.pdf" target="cvpr-2019-3d-local"><b><h6><font color="#C45906" size="3">Article in PDF</font></h6></b></a></p>
									</li>                         
                                    <div class="infoPost col c2-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-pub">
                                                <img src="img/pub/capsule.JPG" alt="3D Point Capsule Networks" title="3D Point Capsule Networks" />
											</a></li>
										</ul>
									</div>
                                    
                                    <li class="first">
										<h5>3D Point Capsule Networks<span class="period"></span></h5>
                                        <p><strong> CVPR 2019</strong>: IEEE Conference on Computer Vision and Pattern Recognition, Long Beach, USA, 2019</p>
										<h6><i class="fa fa-user"></i>Yongheng Zhao, Tolga Birdal, Haowen Deng and Federico Tombari</h6>
                                        <p>In this paper, we propose 3D point-capsule networks, an auto-encoder designed to process sparse 3D point clouds while preserving spatial arrangements of the input data. 3D capsule networks arise as a direct consequence of our unified formulation of the common 3D auto-encoders. The dynamic routing scheme and the peculiar 2D latent space deployed by our capsule networks bring in improvements for several common point cloud-related tasks, such as object classification, object reconstruction and part segmentation as substantiated by our extensive evaluations. Moreover, it enables new applications such as part interpolation and replacement.</p>
                                        <p><a href="https://arxiv.org/pdf/1812.10775.pdf" target="cvpr-2019-3d-point"><b><h6><font color="#C45906" size="3">Article in PDF</font></h6></b></a></p>
									</li>                         
                                    <div class="infoPost col c2-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-pub">
                                                <img src="img/pub/neurips2018.JPG" alt="Pose Graph Optimization" title="Probabilistic Pose Graph Optimization" />
											</a></li>
										</ul>
									</div>
                                    
                                    <li class="first">
										<h5>Bayesian Pose Graph Optimization via Bingham Distributions and Tempered Geodesic MCMC<span class="period"></span></h5>
                                        <p><strong> NeurIPS 2018</strong>: 32nd Conference on Neural Information Processing Systems, Montréal, Canada, 2018</p>
										<h6><i class="fa fa-user"></i>Tolga Birdal, Umut Şimşekli, M. Onur Eken and Slobodan Ilic</h6>
                                        <p>We introduce Tempered Geodesic Markov Chain Monte Carlo (TG-MCMC) algorithm for initializing pose graph optimization problems, arising in various scenarios such as SFM (structure from motion) or SLAM (simultaneous localization and mapping). TG-MCMC is first of its kind as it unites global non-convex optimization on the spherical manifold of quaternions with posterior sampling, in order to provide both reliable initial poses and uncertainty estimates that are informative about the quality of solutions. We devise theoretical convergence guarantees and extensively evaluate our method on synthetic and real benchmarks. Besides its elegance in formulation and theory, we show that our method is robust to missing data, noise and the estimated uncertainties capture intuitive properties of the data.</p>
                                        <p><a href="https://papers.nips.cc/paper/7314-bayesian-pose-graph-optimization-via-bingham-distributions-and-tempered-geodesic-mcmc" target="neurips-2018-bayesian"><b><h6><font color="#C45906" size="3">Article in PDF</font></h6></b></a></p>
									</li>                         
                                    <div class="infoPost col c2-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-pub">
												<img src="img/pub/quadrics.JPG" alt="Quadric Detection" title="Quadric Detection in 3D" />
											</a></li>
										</ul>
									</div>
                                    <li class="first">
										<h5>A Minimalist Approach to Type-Agnostic Detection of Quadrics in Point Clouds<span class="period"></span></h5>
                                        <p><strong>CVPR 2018</strong>: IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, US, 2018</p>
										<h6><i class="fa fa-user"></i>Tolga Birdal, Benjamin Busam, Nassir Navab, Slobodan Ilic and Peter Sturm</h6>
                                        <p>This paper proposes a segmentation-free, automatic and  efficient procedure to detect general geometric quadric forms in point clouds, where clutter and occlusions are inevitable. Our everyday world is dominated by man-made objects which are designed using 3D primitives (such as planes, cones, spheres, cylinders, etc.). These objects are also omnipresent in industrial environments. This gives rise to the possibility of abstracting 3D scenes through primitives, thereby positions these geometric forms as an integral part of perception and high level 3D scene understanding. 
                                            
                                        As opposed to state-of-the-art, where a tailored algorithm treats each primitive type separately, we propose to encapsulate all types in a single robust detection procedure. At the center of our approach lies a closed form 3D quadric fit, operating in both primal & dual spaces and requiring as low as 4 oriented-points. Around this fit, we design a novel, local null-space voting strategy to reduce the 4-point case to 3. Voting is coupled with the famous RANSAC and makes our algorithm orders of magnitude faster than its conventional counterparts. This is the first method capable of performing a generic cross-type multi-object primitive detection in difficult scenes. Results on synthetic and real datasets support the validity of our method</p>
                                        <p><a href="downloads/tolga-birdal-cvpr-2018-quadrics.pdf" target="cvpr-2018-quadrics"><b><h6><font color="#C45906" size="3">Article in PDF</font></h6></b></a></p>
									</li>
                                    <div class="infoPost col c2-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-pub">
												<img src="img/pub/ppf-foldnet.JPG" alt="PPF-FoldNET" title="PPF-FoldNET" />
											</a></li>
										</ul>
									</div>
                                    <li class="first">
										<h5>PPF-FoldNet: Unsupervised Learning of Rotation Invariant 3D Local Descriptors<span class="period"></span></h5>
                                        <p><strong>ECCV 2018</strong>: European Conference on Computer Vision, Munich, Germany, 2018</p>
										<h6><i class="fa fa-user"></i>Haowen Deng, Tolga Birdal, Slobodan Ilic</h6>
                                        <p>We present PPF-FoldNet for unsupervised learning of 3D local descriptors on pure point cloud geometry. Based on the folding-based auto-encoding
of well known point pair features, PPF-FoldNet offers many desirable properties:
it necessitates neither supervision, nor a sensitive local reference frame, benefits
from point-set sparsity, is end-to-end, fast, and can extract powerful rotation invariant descriptors. Thanks to a novel feature visualization, its evolution can be
monitored to provide interpretable insights. Our extensive experiments demonstrate that despite having six degree-of-freedom invariance and lack of training
labels, our network achieves state of the art results in standard benchmark datasets
and outperforms its competitors when rotations and varying point densities are
present. PPF-FoldNet achieves 9% higher recall on standard benchmarks, 23%
higher recall when rotations are introduced into the same datasets and finally, a
margin of
> 35% is attained when point density is significantly decreased.</p>
                                        <p><a href="downloads/tolga-birdal-eccv-2018-ppffoldnet.pdf" target="eccv-2018-ppffoldnet"><b><h6><font color="#C45906" size="3">Article in PDF</font></h6></b></a></p>
									</li>
									<div class="infoPost col c2-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-pub">
												<img src="img/pub/ppfnet.JPG" alt="PPFNET" title="PPFNET" />
											</a></li>
										</ul>
									</div>
                                    <li class="first">
										<h5>PPFNet: Global Context Aware Local Features for Robust 3D Point Matching<span class="period"></span></h5>
                                        <p><strong>CVPR 2018</strong>: IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, US, 2018</p>
										<h6><i class="fa fa-user"></i>Haowen Deng, Tolga Birdal, Slobodan Ilic</h6>
                                        <p>We present PPFNet - Point Pair Feature NETwork for deeply learning a globally informed 3D local feature descriptor to find correspondences in unorganized point clouds. PPFNet learns local descriptors on pure geometry and is highly aware of the global context, an important cue in deep learning. Our 3D representation is computed as a collection of point-pair-features combined with the points and normals within a local vicinity. Our permutation invariant network design is inspired by PointNet and sets PPFNet to be ordering-free. As opposed to voxelization, our method is able to consume raw point clouds to exploit the full sparsity. PPFNet uses a novel N-tuple loss and architecture injecting the global information naturally into the local descriptor. It shows that context awareness also boosts the local feature representation. Qualitative and quantitative evaluations of our network suggest increased recall, improved robustness and invariance as well as a vital step in the 3D descriptor extraction performance.</p>
                                        <p><a href="downloads/tolga-birdal-cvpr-2018-ppfnet.pdf" target="cvpr-2018-ppfnet"><b><h6><font color="#C45906" size="3">Article in PDF</font></h6></b></a></p>
									</li>
                                    <div class="infoPost col c2-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-pub">
												<img src="img/pub/surveyMotion3DV2018.JPG" alt="3D Motion Interpolation" title="Survey of 3D Motion Interpolation" />
											</a></li>
										</ul>
									</div>
                                    <li class="first">
										<h5>Survey of Higher Order Rigid Body Motion Interpolation Methods for Keyframe Animation and Continuous-Time Trajectory Estimation<span class="period"></span></h5>
                                        <p><strong> 3DV 2018</strong>: International Conference on 3D Vision, Verona, Italy, 2018</p>
										<h6><i class="fa fa-user"></i>Adrian Haarbach, Tolga Birdal, Slobodan Ilic</h6>
                                        <p>In this survey we carefully analyze the characteristics of higher order rigid body motion interpolation methods to obtain a continuous trajectory from a discrete set of poses. We first discuss the tradeoff between continuity, local control and approximation of classical Euclidean interpolation schemes such as Bezier and B-splines. The benefits of the manifold of unit quaternions SU(2), a double-cover of rotation matrices SO(3), as rotation parameterization are presented, which allow for an elegant formulation of higher order orientation interpolation with easy analytic derivatives, made possible through the Lie Algebra su(2) of pure quaternions and the cumulative form of cubic B-splines. The same construction scheme is then applied for joint interpolation in the full rigid body pose space, which had previously been done for the matrix representation SE(3) and its twists, but not for the more efficient unit dual quaternion DH1 and its screw motions. Both suffer from the effects of coupling translation and rotation that have mostly been ignored by previous work. We thus conclude that split interpolation in R3 × SU(2) is preferable for most applications. Our final runtime experiments show that joint interpolation in SE(3) is 2 times and in DH1 1.3 times slower - which furthermore justifies our suggestion from a practical point of view.</p>
                                        <p><a href="http://www.adrian-haarbach.de/interpolation-methods/" target="3d-motion-interpolation"><b><h6><font color="#C45906" size="3">Project Page</font></h6></b></a></p>
									</li> 
                                    <div class="infoPost col c2-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-pub">
												<img src="img/pub/reconstruct.JPG" alt="3D CAD Reconstruction" title="3D CAD Reconstruction" />
											</a></li>
										</ul>
									</div>
									<li class="first">
										<h5>CAD Priors for Accurate and Flexible Instance Reconstruction<span class="period"></span></h5>
                                        <p>ICCV 2017: IEEE International Conference on Computer Vision, Venice, Italy, 2017</p>
										<h6><i class="fa fa-user"></i>Tolga Birdal, Slobodan Ilic</h6>
                                        <p>We present an efficient and automatic approach for accurate instance reconstruction of big 3D objects from multiple, unorganized and unstructured point clouds, in presence of dynamic clutter and occlusions. In contrast to conventional scanning, where the background is assumed to be rather static, we aim at handling dynamic clutter where the background drastically changes during object scanning. Currently, it is tedious to solve this problem with available methods unless the object of interest is first segmented out from the rest of the scene. We address the problem by assuming the availability of a prior CAD model, roughly resembling the object to be reconstructed. This assumption almost always holds in applications such as industrial inspection or reverse engineering. With aid of this prior acting as a proxy, we propose a fully enhanced pipeline, capable of automatically detecting and segmenting the object of interest from scenes and creating a pose graph, online, with linear complexity. This allows initial scan alignment to the CAD model space, which is then refined without the CAD constraint to fully recover a high fidelity 3D reconstruction, accurate up to the sensor noise level. We also contribute a novel object detection method, local implicit shape models (LISM) and give a fast verification scheme. We evaluate our method on multiple datasets, demonstrating the ability to accurately reconstruct objects from small sizes up to 125m3.</p>
                                        <p><a href="downloads/tolga-birdal-iccv-2017-cad-priors.pdf" target="iccv-2017-cad-priors"><b><h6><font color="#C45906" size="3">Article in PDF</font></h6></b></a></p>
									</li>
									<div class="infoPost col c2-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-pub">
												<img src="img/pub/dualquat.JPG" alt="Dual Quaternions Pose Filter" title="Dual Quaternions Pose Filter" />
											</a></li>
										</ul>
									</div>
									<li class="first">
										<h5>Camera Pose Filtering with Local Regression Geodesics on the Riemannian Manifold of Dual Quaternions<span class="period"></span></h5>
                                        <p>ICCV 2017 Workshop on Multiview Relationships in 3D Data, Venice, Italy, 2017</p>
										<h6><i class="fa fa-user"></i>Benjamin Busam, Tolga Birdal and Slobodan Ilic</h6>
                                        <p>Time-varying, smooth trajectory estimation is of great interest to the vision community for accurate and well behaving 3D systems. In this paper, we propose a novel principal component local regression filter acting directly on the Riemannian manifold of unit dual quaternions DH1. We use a numerically stable Lie algebra of the dual quaternions together with exp and log operators to locally linearize the 6D pose space. Unlike state of the art path smoothing methods which either operate on SO(3) of rotation matrices or the hypersphere H1 of quaternions, we treat the orientation and translation jointly on the dual quaternion quadric in the 7-dimensional real projective space RP7. We provide an outlier-robust IRLS algorithm for generic pose filtering exploiting this manifold structure. Besides our theoretical analysis, our experiments on synthetic and real data show the practical advantages of the manifold aware filtering on pose tracking and smoothing.</p>
                                        <p><a href="downloads/tolga-birdal-iccvw-2017-dual-quaternions.pdf" target="iccv-2017-pose-filter"><b><h6><font color="#C45906" size="3">Article in PDF</font></h6></b></a></p>
									</li>
									<div class="infoPost col c2-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-pub">
												<img src="img/pub/sampling.JPG" alt="3D Point Sampling" title="3D Point Sampling" />
											</a></li>
										</ul>
									</div>
									<li class="first">
										<h5>A Point Sampling Algorithm for 3D Matching of Irregular Geometries<span class="period"></span></h5>
                                        <p>IROS 2017: IEEE International Conference on Computer Vision, Vancouver, Canada, 2017</p>
										<h6><i class="fa fa-user"></i>Tolga Birdal, Slobodan Ilic</h6>
                                        <p>We present a 3D mesh re-sampling algorithm, carefully tailored for 3D object detection using point pair features (PPF). Computing a sparse representation of objects is critical for the success of state-of-the-art object detection, recognition and pose estimation methods. Yet, sparsity needs to preserve fidelity. To this end, we develop a simple, yet very effective point sampling strategy for detection of any CAD model through geometric hashing. Our approach relies on rendering the object coordinates from a set of views evenly distributed on a sphere. Actual sampling takes place on 2D domain over these renderings; the resulting samples are efficiently merged in 3D with the aid of a special voxel structure and relaxed with Lloyd iterations. The generated vertices are not concentrated only on critical points, as in many keypoint extraction algorithms, and there is even spacing between selected vertices. This is valuable for quantization based detection methods, such as geometric hashing of point pair features. The algorithm is fast and can easily handle the elongated/acute triangles and sharp edges typically existent in industrial CAD models, while automatically pruning the invisible structures. We do not introduce structural changes such as smoothing or interpolation and sample the normals on the original CAD model, achieving the maximum fidelity. We demonstrate the strength of this approach on 3D object detection in comparison to similar sampling algorithms.</p>
                                        <p><a href="downloads/tolga-birdal-iros-2017-cad-sampling.pdf" target="iros-2017-cad-paper"><b><h6><font color="#C45906" size="3">Article in PDF</font></h6></b></a></p>
									</li>
									<div class="infoPost col c2-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-pub">
												<img src="img/pub/xtag.JPG" alt="X-Tag" title="X-Tag" />
											</a></li>
										</ul>
									</div>
                                    <li class="first">
										<h5>X-Tag: A Fiducial Tag for Flexible and Accurate Bundle Adjustment<span class="period"></span></h5>
                                        <p>3DV 2016: IEEE International Conference on 3D Vision (3DV), Stanford, CA, 2016</p>
										<h6><i class="fa fa-user"></i>Tolga Birdal, Ievgeniia Dobryden, Slobodan Ilic</h6>
                                        <p>In this paper we design a novel planar 2D fiducial
marker and develop fast detection algorithm aiming easy camera calibration and precise 3D reconstruction at the marker locations via the bundle adjustment. Even though an abundance of planar fiducial markers have been made and used in various tasks, none of them has properties necessary to solve the aforementioned tasks. Our marker, Xtag, enjoys a novel design, coupled with very efficient and robust detection scheme, resulting in a reduced number of false positives. This is achieved by constructing markers with random circular features in the image domain and encoding them using two true perspective invariants: crossratios and intersection preservation constraints. To detect the markers, we developed an effective search scheme, similar to Geometric Hashing and Hough Voting, in which the marker decoding is cast as a retrieval problem. We apply our system to the task of camera calibration and bundle adjustment. With qualitative and quantitative experiments, we demonstrate the robustness and accuracy of X-tag in spite of blur, noise, perspective and radial distortions, and showcase camera calibration, bundle adjustment and 3d fusion of depth data from precise extrinsic camera poses.</p>
                                        <p><a href="downloads/tolga-birdal-3dv-2016-xtag.pdf" target="3dv-2016-xtag"><b><h6><font color="#C45906" size="3">Article in PDF</font></h6></b></a></p>
									</li>
                                    <div class="infoPost col c2-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-pub">
												<img src="img/pub/camgroups.JPG" alt="Sparse Coodrinate Measurement" title="Sparse Coodrinate Measurement" />
											</a></li>
										</ul>
									</div>
                                    <li class="first">
										<h5>Online Inspection of 3D Parts via a Locally Overlapping Camera Network<span class="period"></span></h5>
                                        <p>WACV 2016: IEEE Winter Conference on Applications of Computer Vision</p>
										<h6><i class="fa fa-user"></i>Tolga Birdal, Emrah Bala, Tolga Eren, Slobodan Ilic</h6>
										<p>The raising standards in manufacturing demands reliable and fast industrial quality control mechanisms. This
paper proposes an accurate, yet easy to install multi-view,
close range optical metrology system, which is suited to online operation. The system is composed of multiple static,
locally overlapping cameras forming a network. Initially,
these cameras are calibrated to obtain a global coordinate
frame. During run-time, the measurements are performed
via a novel geometry extraction techniques coupled with an
elegant projective registration framework, where 3D to 2D
fitting energies are minimized. Finally, a non-linear regression is carried out to compensa te for the uncontrollable errors. We apply our pipeline to inspect various geometrical structures found on automobile parts. While presenting
the implementation of an involved 3D metrology system, we
also demonstrate that the resulting inspection is as accurate
as 0 .2 mm, repeatable and much faster, compared to the existing methods such as coordinate measurement machines
(CMM) or ATOS.</p>
                                        <p><a href="downloads/birdal-wacv-2016.pdf" target="wacv-paper"><b><h6><font color="#C45906" size="3">Article in PDF</font></h6></b></a></p>
									</li>
                                    <div class="infoPost col c2-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-pub">
												<img src="img/pub/ppf.JPG" alt="Point Pair Features" title="Point Pair Features" />
											</a></li>
										</ul>
									</div>
                                    <li class="first">
										<h5>Point Pair Features Based Object Detection and Pose Estimation Revisited<span class="period"></span></h5>
                                        <p>3DV 2015: IEEE International Conference on 3D Vision, Lyon, France</p>
										<h6><i class="fa fa-user"></i>Tolga Birdal, Slobodan Ilic</h6>
										<p>We present a revised pipe-line of the existing 3D object detection and pose estimation framework based on point
pair feature matching. This framework proposed to represent 3D target object using self-similar point pairs, and then
matching such model to 3D scene using efficient Hough-like
voting scheme operating on the reduced pose parameter
space. Even though this work produces great results and
motivated a large number of extensions, it had some general 
shortcoming like relatively high dimensionality of the search
space, sensitivity in establishing 3D correspondences, having performance drops in presence of many outliers and low
density surfaces. <br>
                                            
In this paper, we explain and address these drawbacks
and propose new solutions within the existing framework. In
particular, we propose to couple the object detection with a
coarse-to-fine segmentation, where each segment is subject
to disjoint pose estimation. During matching, we apply
a weighted Hough voting and an interpolated recovery of
pose parameters. Finally, all the generated hypothesis are
tested via an occlusion-aware ranking and sorted. We argue
that such a combined pipeline simultaneously boosts the
detection rate and reduces the complexity, while improving
the accuracy of the resulting pose. Thanks to such enhanced
pose retrieval, our verification doesn’t necessitate ICP and
thus achieves better compromise of speed vs accuracy. We
demonstrate our method on existing datasets as well as on
our scenes. We conclude that via the new pipe-line, point
pair features can now be used in more challenging scenarios.</p>
                                        <p><a href="downloads/birdal-3dv-2015.pdf" target="3dv-paper"><b><h6><font color="#C45906" size="3">Article in PDF</font></h6></b></a></p>
									</li>
                                    <div class="infoPost col c2-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-pub">
												<img src="img/pub/barcode.JPG" alt="Barcode Decoding" title="Barcode Decoding" />
											</a></li>
										</ul>
									</div>
                                    <li class="first">
										<h5>A Unified Probabilistic Framework For Robust Decoding Of Linear Barcodes<span class="period"></span></h5>
                                        <p>ICASSP 2015: IEEE International Conference on Acoustics, Speech, and Signal Processing, Brisbane, Australia</p>
										<h6><i class="fa fa-user"></i>Umut Simsekli, Tolga Birdal</h6>
										<p>Both consumer market and manufacturing industry makes heavy use of 1D (linear) barcodes. From helping the visually impaired to identifying the products to industrial automated industry management, barcodes are the prevalent source of item tracing technology. Because of this ubiquitous use, in recent years, many algorithms have been proposed targeting barcode decoding from high-accessibility devices such as cameras. However, the current methods have at least one of the two major problems: 1) they are sensitive to blur, perspective/lens distortions, and non-linear deformations, which often occur in practice, 2) they are specifically designed for a specific barcode symbology (such as UPC-A) and cannot be applied to other symbologies. In this paper, we aim to address these problems and present a dynamic Bayesian network in order to robustly model all kinds of linear progressive barcodes. We apply our method on various barcode datasets and compare the performance with the state-of-the-art. Our experiments show that, as well as being applicable to all progressive barcode types, our method provides competitive results in clean UPC-A datasets and outperforms the state-of-the-art in difficult scenarios.</p>
                                        <p><a href="downloads/tolga-birdal-icassp-2015.pdf" target="icassp-paper"><b><h6><font color="#C45906" size="3">Article in PDF</font></h6></b></a></p>
									</li>
                                    
									<li class="first">
										<h5>Towards A Complete Framework For Deformable Surface Recovery Using RGBD Cameras<span class="period"></span></h5>
                                        <p>IROS'12 Workshop on Color-Depth Fusion in Robotics</p>
										<h6><i class="fa fa-user"></i>Tolga Birdal, Diana Mateus Slobodan Ilic</h6>
										<p>In this paper, we study the problem of 3D deformable
surface tracking with RGBD cameras, specifically
Microsofts Kinect. In order to achieve this we introduce a
fully automated framework that includes several components:
automatic initialization based on segmentation of the object of
interest, then robust range flow that guides deformations of
the object of interest and finally representation of the results
using mass-spring model. The key contribution is extension of
the range flow work of Spies and Jahne [1] that combines
Lucas-Kanade [2] and Horn and Shunk [3] approaches for
RGB-D data, makes it to converge faster and incorporates color
information with multichannel formulation. We also introduced
a pipeline for generating synthetic data and performed error
analysis and comparison to original range flow approach. The
results show that our method is accurate and precise enough
to track significant deformation smoothly at near real-time performance. </p>
                                        <p><a href="downloads/tolga-birdal-iros-2012-submission.pdf" target="ıros-paper"><b><h6><font color="#C45906" size="3">Article in PDF</font></h6></b></a></p>
									</li>
                                    <div class="infoPost col c2-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-pub">
												<img src="img/pub/vector.JPG" alt="Image Vectorization" title="Image Vectorization" />
											</a></li>
										</ul>
									</div>
                                     <li class="first">
										<h5>A Novel Method For Image Vectorization<span class="period"></span></h5>
                                        <p>arXiv:1403.0728</p>
										<h6><i class="fa fa-user"></i>Tolga Birdal, Emrah Bala</h6>
										<p>Vectorization of images is a key concern uniting computer graphics
and computer vision communities. In this paper we are presenting a novel idea for efficient, customizable vectorization of raster
images, based on Catmull Rom spline fitting. The algorithm maintains a good balance between photo-realism and photo abstraction,
and hence is applicable to applications with artistic concerns or applications where less information loss is crucial. The resulting algorithm is fast, parallelizable and can satisfy general soft realtime
requirements. Moreover, the smoothness of the vectorized images
aesthetically outperforms outputs of many polygon-based methods.
                                <p><a href="downloads/tolga-birdal-realtime-vectorization.pdf" alt="A Novel Method For Image Vectorization" title="A Novel Method For Image Vectorization" target="vector-paper"><b><h6><font color="#C45906" size="3">Article in PDF</font></h6></b></a></p>
									</li>
                                    <div class="infoPost col c2-1 first">
										<ul class="da-thumbs">
											<li><a class="box-img-pub">
												<img src="img/pub/felic.JPG" alt="FELIC" title="FELIC" />
											</a></li>
										</ul>
									</div>
                                <li class="first">
										<h5>Flow Enhancing Line Integral Convolution Filter<span class="period"></span></h5>
                                        <p>ICIP 2010</p>
										<h6><i class="fa fa-user"></i>Tolga Birdal, Emrah Bala</h6>
										<p>Visualization of vector ﬁelds is an operation used in many
ﬁelds such as science, art and image processing. Lately, line
integral convolution (LIC) technique [1], which is based on
locally ﬁltering an input image along a curved stream line in
a vector ﬁeld, has become very popular in this area because of
its local and robust characteristics. For smoothing and texture
generation, used vector ﬁeld deeply affects the output of LIC
method. We propose a new vector ﬁeld based on ﬂow ﬁelds
to use with LIC. This new hybrid technique is called ﬂow
enhancing line integral convolution ﬁltering (FELIC) and it
is highly capable of smoothing an image and generating high
ﬁdelity textures. </p>
                                    <p><a href="downloads/tolga-birdal-flow-lic-icip-2010.pdf" alt="Flow Enhancing Line Integral Convolution Filter" title="Flow Enhancing Line Integral Convolution Filter" target="icip_paper"><b><h6><font color="#C45906" size="3">Article in PDF</font></h6></b></a></p>
									</li>
                                    
                                    <li class="first">
										<h5>A Factorization Based Recommender System for Online Services (Çevrimiçi Servisler için Ayrısım Tabanlı Tavsiye Sistemi)<span class="period"></span></h5>
                                        <p>SIU 2013 Alper Atalay Best Paper Award Ranked 3</p>
										<h6><i class="fa fa-user"></i>Umut Simsekli, Tolga Birdal, Emre Koc, A. Taylan Cemgil</h6>
										<p>Along with the growth of the Internet, automatic
recommender systems have become popular. Due to being intuitive and useful, factorization based models, including the
Nonnegative Matrix Factorization (NMF) model, are one of the
most common approaches for building recommender systems. In
this study, we focus on how a recommender system can be built for
online services and how the parameters of an NMF model should
be selected in a recommender system setting. We first present a
general system architecture in which any kind of factorization
model can be used. Then, in order to see how accurate the NMF
model fits the data, we randomly erase some parts of a real data
set that is gathered from an online food ordering service, and
we reconstruct the erased parts by using the NMF model. We
report the mean squared errors for different parameter settings
and different divergences. </p>
                                        <p><a href="downloads/siu2013recommendation.pdf" target="siu_paper"><b><h6><font color="#C45906" size="3">Article in PDF</font></h6></b></a></p>
									</li>
                                    
                                    <li class="first">
										<h5>Real-time automated road, lane and car detection for autonomous driving<span class="period"></span></h5>
                                        <p>DSP in Cars 2007</p>
										<h6><i class="fa fa-user"></i>Tolga Birdal, Aytul Ercil</h6>
										<p>In this paper, we discuss a vision-based system for 
autonomous guidance of vehicles. An autonomous 
intelligent vehicle has to perform a number of 
functionalities. Segmentation of the road, determining the 
boundaries to drive in and recognizing the vehicles and 
obstacles around are the main tasks for vision guided 
vehicle navigation. In this article we propose a set of 
algorithms, which lead to the solution of road and vehicle 
segmentation using data from a color camera. The 
algorithms described here combine gray value difference 
and texture analysis techniques to segment the road from 
the image, several geometric transformations and contour 
processing algorithms are used to segment lanes, and 
moving cars are extracted with the help of background 
modeling and estimation. The techniques developed have 
been tested in real road images and the results are 
presented.</p>
                                        <p><a href="downloads/dspincars2007.pdf" target="dspincars_paper"><b><h6><font color="#C45906" size="3">Article in PDF</font></h6></b></a></p>
									</li>
                                    
								</ul>
								</div>
							<div class="col c1-1 first">
								<h4>Patents</h4>
								<ul class="attributes">
                                                                        
                                     <li class="first">
										<h5>METHOD AND SYSTEM FOR GENERATING ONLINE CARTOON OUTPUTS<span class="period"></span></h5>
                                        <p>United States 20090219298 - 2009</p>
										<h6><i class="fa fa-user"></i>Tolga Birdal, Mehmet Ozkanoglu, Abdi Tekin Tatar</h6>
										<p>A method and system for generating user-accessible effects. The method includes receiving a library of operators, each operator including a set of operations performable on an image. The method includes receiving an effect definition from a designer via a graphical user interface, wherein the effect definition includes a set of operators from the library to be executed on a user-provided image and parameters associated with each operator. The method includes saving the effect definition to an accessible memory. The method includes uploading the effect definition to a server wherein the effect definition is accessible to a user over a network.
</p><p><a href="https://www.google.com/patents/US20090219298" target="patent1"><b><h6><font color="#C45906" size="3">Visit Patent Website</font></h6></b></a></p>
									</li>
                                    
									<li class="first">
										<h5>METHOD AND SYSTEM FOR PROVIDING AN IMAGE EFFECTS INTERFACE<span class="period"></span></h5>
                                        <p>United States Patent 20100223565 - 2010</p>
										<h6><i class="fa fa-user"></i>Tolga Birdal, Emrah Bala, Emre Koc, Mehmet Ozkanoglu, Abdi Tekin Tatar</h6>
										<p>A method and system for generating user-accessible effects. The method includes receiving a library of operators, each operator including a set of operations performable on an image. The method includes receiving an effect definition from a designer via a graphical user interface, wherein the effect definition includes a set of operators from the library to be executed on a user-provided image and parameters associated with each operator. The method includes saving the effect definition to an accessible memory. The method includes uploading the effect definition to a servers wherein the effect definition is accessible to a user over a network
</p><p><a href="http://www.faqs.org/patents/app/20100223565#ixzz13Vi7rRZM" target="patent2"><b><h6><font color="#C45906" size="3">Visit Patent Website</font></h6></b></a></p>
									</li>                                    
                                   
								</ul>
								</div>
                            <div class="col c1-1 first">
								<h4>Thesis</h4>
								<ul class="attributes">
									<li class="first">
										<h5>3D Deformable Surface Recovery Using RGBD
Cameras<span class="period"></span></h5>
                                        <p>Master Thesis At Technical University of Munich, 2011</p>
										<h6><i class="fa fa-user"></i>Tolga Birdal</h6>
										<p>Deformable surfaces are ubiquitous in real world and thus are of great interest to computer vision researchers. They exist in various forms such as packets, flags, clothing, organs, bodies and etc. For this reason, their application areas are extensive ranging from sports to entertainment, from medical imaging to machine vision. While the research in the area is quite new, many advanced methods are already being developed. Most of these methods rely on stereo computations or try to solve the under-constrained problem of recovering deformations from monocular scenes. Recently, there has been an increasing number of depth (RGBD) cameras available at commodity prices. These cameras can usually capture both color and depth images in real-time, with limited resolution and accuracy. <br>
In this thesis, we study the problem of 3D deformable surface reconstruction with such RGBD cameras. Specifically, we base our implementation on Microsoft’s Kinect. Our method can handle the global and significant deformations. We deliver our novel method as an easy tool for learning deformations, material invariant tracking and naturally a generic algorithm for 3D deformation recovery.<br>
The contribution of this thesis is three-fold. We start by proposing a new but straightforward algorithm for automatically segmenting a surface of interest from RGB-D data, which we use to initialize our tracker. Next, we take an existing surface flow framework called range flow, then improve and adapt it for our case of 3D deformation capture. This step is nothing but a surface-flow tracker. Finally, to make this tracker more robust against noise, we propose a mass spring model based post filter. The post processing step acts as a model based constraint which attracts the individual vertices together to form an inextensible tracking capability. Our post filter is chosen to be
a cloth model, which is very well-studied in the realm of computer graphics. Last but not least, we thoroughly discuss the results and how the system behaves. The algorithm performs soft-real-time when implemented on a CPU. We also explain the parallelization aspects while paving the way for a real-time implementation on the GPU. Overall, we present a fundamental system for 3D tracking of deformable surfaces. As well as being
extendible, we show that there is also room for various improvements and advancements.
</p><p><a href="downloads/tolga-birdal-master-thesis.pdf" target="thesis_1"><b><h6><font color="#C45906" size="3">My Masters Thesis</font></h6></b></a></p>
									</li>
                                   
								</ul>
								</div>
							<div class="clear"></div>
						</div>
					</section>
					<section id="links-page" class="content">
						<div class="inner">
								<ul class="about">
                                    <h4>Links</h4>
							<h5 class="perido">
                                <li>
                                
                                <h5 class="subtitle"><a href="https://tbirdal.blogspot.de" target="matlab_page">My Rarely Updated Blog &rarr;</a>  </h5>
                                    
                                <h5 class="subtitle"><a href="http://www.mathworks.com/matlabcentral/fileexchange/authors/50252" target="matlab_page">My Profile At MATLAB File Exchange &rarr;</a>  </h5>
                                
                                <h5 class="subtitle"><a href="http://www.codeproject.com/script/Articles/MemberArticles.aspx?amid=1501114" target="cp_page">My Profile At CodeProject &rarr;</a>  </h5>
                                
                                <h5 class="subtitle"><a href="http://www.youtube.com/channel/UCMSqZYDAmbiaAhyvLPJGhsg" target="youtube_page">My YouTube Channel &rarr;</a>  </h5>
                              </li>
							</h5>
                                    </ul>
                            
                            <ul class="about">
                                    <h4>Conferences, Talks and Events Attended</h4>
							<h5>
                                <li class="first">Presented @ IROS 2012, SIU 2013, 3DV 2015, 3DV 2016, WACV 2016, IROS 2017, CVPR 2017, ICCV 2017, CVPR 2018, ECCV 2018, NIPS 2018</li>
                                <li class="first">Demonstrations @ Techcrunch 40 2007, Techcrunch 50 2008, GTS Pitch Competition 2009</li>
                                <li class="first">Exhibited @ World of Industry 2012</li>
                                <li class="first">Invited Speaker, Telekom ParisTech, 2017 Paris, France</li>
                                <li class="first">Invited Speaker, EECVC 2017/2018, Odessa, Ukraine</li>
                                <li class="first">Invited Speaker, 1st EMVA Forum, 2016, Heidelberg, Germany</li>
                                <li class="first">ICVSS 2012, 2013, 2015 (International Computer Vision Summer School)  – Successful Completion Certificates - Sicily</li>
                                <li class="first">IPAM GSS 2013 @UCLA (Computer Vision Graduate Summer School) – NSF Scholarship - Los Angeles, USA</li>
                                <li class="first">World of Industry 2012 Exhibitor, World of Industry 2013 Exhibitor - Istanbul</li>
                                <li class="first">Stuttgart Vision Fair 2007, 2010, 2011, 2012 - Stutgart, Germany</li>
                                <li class="first">NVISION 2008 - San Jose, USA</li>
                                <li class="first">ARCS 2008 - Dresden, Germany</li>
                                <li class="first">MVTec Halcon 8.0 Training – Munich, Germany</li>
                                <li class="first">Hannover Industrial Fair (both Exhibitor & Visitor) - Hannover, Germany</li> 
                                <li class="first">ARIF Innovation Festival @ Sabanci Univesity (Exhibitor) - Istanbul, Turkey</li>
                                <li class="first">SIU 2007 - Signal Processing and Communications Conference - Antalya, Turkey</li>
                                <li class="first">Siemens Simatic Machine Vision Workshop -  Nurnberg, Germany</li>
                                <li class="first">Intel Multi Core Programming - Ankara, Turkey</li>
							</h5>
                                    </ul>
                            <ul class="about">
                                    <h4>Voluntary Services</h4>
							<h5>
                                <li class="first">Associate Editor of Springer Journal of Real-Time Image Processing</li>
                                <li class="first">Reviewer for IEEE Transactions of Pattern Analysis and Machine Intelligence (T-PAMI)</li>
                                <li class="first">Reviewer for IEEE Computer Vision and Pattern Recognition (CVPR) Conference</li>
                                <li class="first">Reviewer for Machine Vision and Applications</li>                            
							</h5>
                                    </ul>

</div>
					</section>					
				</section>
			</div>
			<div class="clear"></div>
			<section id="copyright">
				<p>Copyright © 2013 Tolga Birdal<a class="to-top">Back to top <i class="fa fa-arrow-up"></i>&nbsp;</a></p>
			</section>
		</section>
	</div>
	<script src="js/jquery-1.10.2.min.js"></script>
	<script src="js/vendor/modernizr-2.6.2.min.js"></script>
	<script>window.jQuery || document.write('<script src="js/vendor/jquery-1.10.2.min.js"><\/script>')</script>
	<script src="js/plugins.js"></script>
	<script src="js/jquery.mousewheel.min.js"></script>
	<script src="js/mwheelIntent.min.js"></script>
	<script src="js/jquery.jscrollpane.min.js"></script>
	<script src="js/bjqs-1.3.min.js"></script>
	<script src="js/jquery.hoverdir.min.js"></script>
	<script>$(function() { $('.da-thumbs > li').each( function() { $(this).hoverdir(); } ); });</script>
	<script src="js/jquery.lightbox.min.js"></script>
	<script src="js/jquery.validate.min.js"></script>
	<script src="js/myscripts.min.js"></script>
</body>
</html>